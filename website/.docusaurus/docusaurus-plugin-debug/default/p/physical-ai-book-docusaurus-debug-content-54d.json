{"allContent":{"docusaurus-plugin-css-cascade-layers":{},"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/physical-ai-book/docs","tagsPath":"/physical-ai-book/docs/tags","editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"C:\\Users\\Pcw\\physical-ai-book\\website\\sidebars.ts","contentPath":"C:\\Users\\Pcw\\physical-ai-book\\website\\docs","docs":[{"id":"appendix","title":"Appendix","description":"This appendix provides quick reference guides and supplementary information to assist you in your robotics development journey.","source":"@site/docs/appendix.md","sourceDirName":".","slug":"/appendix","permalink":"/physical-ai-book/docs/appendix","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/appendix.md","tags":[],"version":"current","sidebarPosition":101,"frontMatter":{"title":"Appendix","sidebar_position":101},"sidebar":"tutorialSidebar","previous":{"title":"Glossary","permalink":"/physical-ai-book/docs/glossary"}},{"id":"capstone-project/project-walkthrough","title":"1. Capstone Project Walkthrough","description":"Congratulations on making it to the Capstone Project! This is where you'll bring together all the knowledge and skills you've gained throughout the textbook to build a fully autonomous humanoid assistant in a simulated environment.","source":"@site/docs/capstone-project/1-project-walkthrough.md","sourceDirName":"capstone-project","slug":"/capstone-project/project-walkthrough","permalink":"/physical-ai-book/docs/capstone-project/project-walkthrough","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/capstone-project/1-project-walkthrough.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"1. Capstone Project Walkthrough","sidebar_label":"Project Walkthrough","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Exercises","permalink":"/physical-ai-book/docs/module-4-vla/exercises"},"next":{"title":"Glossary","permalink":"/physical-ai-book/docs/glossary"}},{"id":"glossary","title":"Glossary","description":"This glossary provides definitions for key terms and acronyms used throughout the \"Physical AI & Humanoid Robotics\" textbook.","source":"@site/docs/glossary.md","sourceDirName":".","slug":"/glossary","permalink":"/physical-ai-book/docs/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/glossary.md","tags":[],"version":"current","sidebarPosition":100,"frontMatter":{"title":"Glossary","sidebar_position":100},"sidebar":"tutorialSidebar","previous":{"title":"Project Walkthrough","permalink":"/physical-ai-book/docs/capstone-project/project-walkthrough"},"next":{"title":"Appendix","permalink":"/physical-ai-book/docs/appendix"}},{"id":"intro","title":"Introduction","description":"Welcome to the frontier of artificial intelligence and robotics. This open-source textbook is your guide to building intelligent humanoid robots that can perceive, understand, and interact with the complex physical world. As we stand on the cusp of a new era in robotics, the ability to bridge the gap between AI algorithms and physical embodiment has never been more critical.","source":"@site/docs/intro.mdx","sourceDirName":".","slug":"/intro","permalink":"/physical-ai-book/docs/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/intro.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Introduction"},"sidebar":"tutorialSidebar","next":{"title":"Introduction to ROS 2","permalink":"/physical-ai-book/docs/module-1-ros2/intro-to-ros2"}},{"id":"module-1-ros2/ai-agents-to-controllers","title":"5. From AI Agents to Robot Controllers","description":"We've defined what our robot looks like with URDF, and we know how to write Python nodes with rclpy. Now, how do we command the robot to move?","source":"@site/docs/module-1-ros2/5-ai-agents-to-controllers.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/ai-agents-to-controllers","permalink":"/physical-ai-book/docs/module-1-ros2/ai-agents-to-controllers","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-1-ros2/5-ai-agents-to-controllers.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"5. From AI Agents to Robot Controllers","sidebar_label":"AI Agents to Controllers","sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Humanoid URDF Models","permalink":"/physical-ai-book/docs/module-1-ros2/humanoid-urdf-models"},"next":{"title":"Exercises","permalink":"/physical-ai-book/docs/module-1-ros2/exercises"}},{"id":"module-1-ros2/exercises","title":"6. Module 1 Exercises","description":"It's time to put your new knowledge into practice. These exercises are designed to solidify your understanding of the core ROS 2 concepts covered in this module.","source":"@site/docs/module-1-ros2/6-exercises.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/exercises","permalink":"/physical-ai-book/docs/module-1-ros2/exercises","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-1-ros2/6-exercises.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"title":"6. Module 1 Exercises","sidebar_label":"Exercises","sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"AI Agents to Controllers","permalink":"/physical-ai-book/docs/module-1-ros2/ai-agents-to-controllers"},"next":{"title":"What is a Digital Twin?","permalink":"/physical-ai-book/docs/module-2-digital-twin/what-is-a-digital-twin"}},{"id":"module-1-ros2/humanoid-urdf-models","title":"4. Describing Your Robot with URDF","description":"So far, we've created abstract nodes that pass data around. But how do we tell ROS what our robot actually looks like? How do we define its shape, its joints, and how all its parts connect?","source":"@site/docs/module-1-ros2/4-humanoid-urdf-models.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/humanoid-urdf-models","permalink":"/physical-ai-book/docs/module-1-ros2/humanoid-urdf-models","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-1-ros2/4-humanoid-urdf-models.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"4. Describing Your Robot with URDF","sidebar_label":"Humanoid URDF Models","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Controlling with rclpy","permalink":"/physical-ai-book/docs/module-1-ros2/rclpy-for-control"},"next":{"title":"AI Agents to Controllers","permalink":"/physical-ai-book/docs/module-1-ros2/ai-agents-to-controllers"}},{"id":"module-1-ros2/intro-to-ros2","title":"1. Introduction to ROS 2","description":"Welcome to the first module of our journey into Physical AI. Before our humanoid robot can learn to see, think, or act, it needs a nervous system. In the world of modern robotics, that nervous system is the Robot Operating System (ROS).","source":"@site/docs/module-1-ros2/1-intro-to-ros2.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/intro-to-ros2","permalink":"/physical-ai-book/docs/module-1-ros2/intro-to-ros2","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-1-ros2/1-intro-to-ros2.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"1. Introduction to ROS 2","sidebar_label":"Introduction to ROS 2","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Introduction","permalink":"/physical-ai-book/docs/intro"},"next":{"title":"Nodes, Topics, Services","permalink":"/physical-ai-book/docs/module-1-ros2/nodes-topics-services"}},{"id":"module-1-ros2/nodes-topics-services","title":"2. Nodes, Topics, Services, & Actions","description":"In the last chapter, we introduced the ROS graph as a network of independent programs. Now, let's break down the four fundamental concepts that make this graph work: Nodes, Topics, Services, and Actions.","source":"@site/docs/module-1-ros2/2-nodes-topics-services.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/nodes-topics-services","permalink":"/physical-ai-book/docs/module-1-ros2/nodes-topics-services","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-1-ros2/2-nodes-topics-services.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"2. Nodes, Topics, Services, & Actions","sidebar_label":"Nodes, Topics, Services","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to ROS 2","permalink":"/physical-ai-book/docs/module-1-ros2/intro-to-ros2"},"next":{"title":"Controlling with rclpy","permalink":"/physical-ai-book/docs/module-1-ros2/rclpy-for-control"}},{"id":"module-1-ros2/rclpy-for-control","title":"3. Writing Your First ROS 2 Node with rclpy","description":"Theory is great, but robotics is all about building things that work. In this chapter, we'll write our first ROS 2 nodes using rclpy, the official Python client library for ROS 2. We'll create a classic \"talker\" (publisher) and \"listener\" (subscriber) to see topics in action.","source":"@site/docs/module-1-ros2/3-rclpy-for-control.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/rclpy-for-control","permalink":"/physical-ai-book/docs/module-1-ros2/rclpy-for-control","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-1-ros2/3-rclpy-for-control.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"3. Writing Your First ROS 2 Node with rclpy","sidebar_label":"Controlling with rclpy","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Nodes, Topics, Services","permalink":"/physical-ai-book/docs/module-1-ros2/nodes-topics-services"},"next":{"title":"Humanoid URDF Models","permalink":"/physical-ai-book/docs/module-1-ros2/humanoid-urdf-models"}},{"id":"module-2-digital-twin/complete-humanoid-simulation","title":"5. Building a Complete Humanoid Simulation","description":"We've learned about physics in Gazebo, rendering in Unity, and simulating sensors. Now it's time to assemble all these components into a complete, end-to-end digital twin of our humanoid robot.","source":"@site/docs/module-2-digital-twin/5-complete-humanoid-simulation.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/complete-humanoid-simulation","permalink":"/physical-ai-book/docs/module-2-digital-twin/complete-humanoid-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-2-digital-twin/5-complete-humanoid-simulation.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"5. Building a Complete Humanoid Simulation","sidebar_label":"Complete Humanoid Simulation","sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Sensor Simulation","permalink":"/physical-ai-book/docs/module-2-digital-twin/sensor-simulation"},"next":{"title":"Exercises","permalink":"/physical-ai-book/docs/module-2-digital-twin/exercises"}},{"id":"module-2-digital-twin/exercises","title":"6. Module 2 Exercises","description":"These exercises will help you master the fundamentals of creating and interacting with robotic simulations in Gazebo. You will need a working ROS 2 and Gazebo installation to complete them.","source":"@site/docs/module-2-digital-twin/6-exercises.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/exercises","permalink":"/physical-ai-book/docs/module-2-digital-twin/exercises","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-2-digital-twin/6-exercises.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"title":"6. Module 2 Exercises","sidebar_label":"Exercises","sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Complete Humanoid Simulation","permalink":"/physical-ai-book/docs/module-2-digital-twin/complete-humanoid-simulation"},"next":{"title":"Intro to Isaac","permalink":"/physical-ai-book/docs/module-3-isaac/intro-to-isaac"}},{"id":"module-2-digital-twin/gazebo-physics","title":"2. Simulating Physics with Gazebo","description":"In the last chapter, we defined a Digital Twin as a physics-based simulation of our robot. Now, let's get our hands dirty with the tool that provides that physics: Gazebo.","source":"@site/docs/module-2-digital-twin/2-gazebo-physics.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/gazebo-physics","permalink":"/physical-ai-book/docs/module-2-digital-twin/gazebo-physics","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-2-digital-twin/2-gazebo-physics.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"2. Simulating Physics with Gazebo","sidebar_label":"Gazebo Physics","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"What is a Digital Twin?","permalink":"/physical-ai-book/docs/module-2-digital-twin/what-is-a-digital-twin"},"next":{"title":"Unity for HRI","permalink":"/physical-ai-book/docs/module-2-digital-twin/unity-for-hri"}},{"id":"module-2-digital-twin/sensor-simulation","title":"4. Simulating Sensors","description":"A robot is blind and deaf without its sensors. A critical function of a digital twin is to generate realistic sensor data that our perception and navigation algorithms can consume. In this chapter, we'll explore how to add and configure common robotic sensors in our simulators.","source":"@site/docs/module-2-digital-twin/4-sensor-simulation.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/sensor-simulation","permalink":"/physical-ai-book/docs/module-2-digital-twin/sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-2-digital-twin/4-sensor-simulation.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"4. Simulating Sensors","sidebar_label":"Sensor Simulation","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Unity for HRI","permalink":"/physical-ai-book/docs/module-2-digital-twin/unity-for-hri"},"next":{"title":"Complete Humanoid Simulation","permalink":"/physical-ai-book/docs/module-2-digital-twin/complete-humanoid-simulation"}},{"id":"module-2-digital-twin/unity-for-hri","title":"3. High-Fidelity Rendering with Unity","description":"Gazebo is a fantastic tool for simulating physics, but its graphics are relatively simple. For many cutting-edge robotics applications, visual realism is not just a \"nice-to-have\"—it's a necessity. This is where game engines like Unity come in.","source":"@site/docs/module-2-digital-twin/3-unity-for-hri.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/unity-for-hri","permalink":"/physical-ai-book/docs/module-2-digital-twin/unity-for-hri","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-2-digital-twin/3-unity-for-hri.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"3. High-Fidelity Rendering with Unity","sidebar_label":"Unity for HRI","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo Physics","permalink":"/physical-ai-book/docs/module-2-digital-twin/gazebo-physics"},"next":{"title":"Sensor Simulation","permalink":"/physical-ai-book/docs/module-2-digital-twin/sensor-simulation"}},{"id":"module-2-digital-twin/what-is-a-digital-twin","title":"1. What is a Digital Twin?","description":"In the first module, we learned how to build the \"nervous system\" of a robot using ROS 2 and describe its physical form using URDF. We even made a virtual model wave at us in RViz.","source":"@site/docs/module-2-digital-twin/1-what-is-a-digital-twin.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/what-is-a-digital-twin","permalink":"/physical-ai-book/docs/module-2-digital-twin/what-is-a-digital-twin","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-2-digital-twin/1-what-is-a-digital-twin.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"1. What is a Digital Twin?","sidebar_label":"What is a Digital Twin?","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Exercises","permalink":"/physical-ai-book/docs/module-1-ros2/exercises"},"next":{"title":"Gazebo Physics","permalink":"/physical-ai-book/docs/module-2-digital-twin/gazebo-physics"}},{"id":"module-3-isaac/ai-controlled-humanoid-brain","title":"6. The AI-Controlled Humanoid Brain","description":"We've assembled a powerful set of tools in this module: a photorealistic simulator (Isaac Sim), a suite of GPU-accelerated perception nodes (Isaac ROS), and a robust navigation stack (Nav2). Now it's time to assemble them into a cohesive \"brain\" for our robot.","source":"@site/docs/module-3-isaac/6-ai-controlled-humanoid-brain.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/ai-controlled-humanoid-brain","permalink":"/physical-ai-book/docs/module-3-isaac/ai-controlled-humanoid-brain","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-3-isaac/6-ai-controlled-humanoid-brain.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"title":"6. The AI-Controlled Humanoid Brain","sidebar_label":"AI-Controlled Humanoid Brain","sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Nav2 Path Planning","permalink":"/physical-ai-book/docs/module-3-isaac/nav2-path-planning"},"next":{"title":"Exercises","permalink":"/physical-ai-book/docs/module-3-isaac/exercises"}},{"id":"module-3-isaac/exercises","title":"7. Module 3 Exercises","description":"The concepts in this module are best understood by working directly with the software. These exercises will guide you through using Isaac Sim and the Isaac ROS GEMs. You will need a computer with a compatible NVIDIA GPU and a full installation of Isaac Sim and Isaac ROS.","source":"@site/docs/module-3-isaac/7-exercises.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/exercises","permalink":"/physical-ai-book/docs/module-3-isaac/exercises","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-3-isaac/7-exercises.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"title":"7. Module 3 Exercises","sidebar_label":"Exercises","sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"AI-Controlled Humanoid Brain","permalink":"/physical-ai-book/docs/module-3-isaac/ai-controlled-humanoid-brain"},"next":{"title":"VLA Future of Robotics","permalink":"/physical-ai-book/docs/module-4-vla/vla-future-of-robotics"}},{"id":"module-3-isaac/intro-to-isaac","title":"1. Introduction to the AI-Robot Brain (NVIDIA Isaac)","description":"Welcome to Module 3. So far, we have built a robot's nervous system with ROS 2 and given it a virtual body in a simulated world. Now, it's time to give it a brain. In modern robotics, the \"brain\" is a complex system of perception, planning, and control algorithms, many of which are powered by AI and accelerated by specialized hardware.","source":"@site/docs/module-3-isaac/1-intro-to-isaac.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/intro-to-isaac","permalink":"/physical-ai-book/docs/module-3-isaac/intro-to-isaac","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-3-isaac/1-intro-to-isaac.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"1. Introduction to the AI-Robot Brain (NVIDIA Isaac)","sidebar_label":"Intro to Isaac","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Exercises","permalink":"/physical-ai-book/docs/module-2-digital-twin/exercises"},"next":{"title":"Isaac Sim Photorealism","permalink":"/physical-ai-book/docs/module-3-isaac/isaac-sim-photorealism"}},{"id":"module-3-isaac/isaac-ros-perception","title":"3. GPU-Accelerated Perception with Isaac ROS","description":"Running a photorealistic simulation in Isaac Sim is only half the story. The data generated by the simulator needs to be processed by our robot's brain. For perception tasks like computer vision and 3D sensing, the amount of data can be enormous, easily overwhelming a CPU.","source":"@site/docs/module-3-isaac/3-isaac-ros-perception.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/isaac-ros-perception","permalink":"/physical-ai-book/docs/module-3-isaac/isaac-ros-perception","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-3-isaac/3-isaac-ros-perception.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"3. GPU-Accelerated Perception with Isaac ROS","sidebar_label":"Isaac ROS Perception","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Sim Photorealism","permalink":"/physical-ai-book/docs/module-3-isaac/isaac-sim-photorealism"},"next":{"title":"VSLAM and Depth","permalink":"/physical-ai-book/docs/module-3-isaac/vslam-and-depth"}},{"id":"module-3-isaac/isaac-sim-photorealism","title":"2. Isaac Sim and Photorealistic Rendering","description":"NVIDIA's Isaac Sim is not just another robotics simulator; it's a platform built for the age of AI. Its core strength lies in its ability to generate physically-based, photorealistic sensor data. This is a game-changer for training and testing the AI models that power modern robots.","source":"@site/docs/module-3-isaac/2-isaac-sim-photorealism.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/isaac-sim-photorealism","permalink":"/physical-ai-book/docs/module-3-isaac/isaac-sim-photorealism","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-3-isaac/2-isaac-sim-photorealism.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"2. Isaac Sim and Photorealistic Rendering","sidebar_label":"Isaac Sim Photorealism","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Intro to Isaac","permalink":"/physical-ai-book/docs/module-3-isaac/intro-to-isaac"},"next":{"title":"Isaac ROS Perception","permalink":"/physical-ai-book/docs/module-3-isaac/isaac-ros-perception"}},{"id":"module-3-isaac/nav2-path-planning","title":"5. Autonomous Navigation with Nav2","description":"We have given our robot the ability to \"see\" and \"locate\" itself in a map. The next logical step is to give it the ability to move from point A to point B on its own. This is the domain of navigation, and in ROS 2, the industry-standard solution is the Navigation2 stack, or Nav2.","source":"@site/docs/module-3-isaac/5-nav2-path-planning.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/nav2-path-planning","permalink":"/physical-ai-book/docs/module-3-isaac/nav2-path-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-3-isaac/5-nav2-path-planning.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"5. Autonomous Navigation with Nav2","sidebar_label":"Nav2 Path Planning","sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"VSLAM and Depth","permalink":"/physical-ai-book/docs/module-3-isaac/vslam-and-depth"},"next":{"title":"AI-Controlled Humanoid Brain","permalink":"/physical-ai-book/docs/module-3-isaac/ai-controlled-humanoid-brain"}},{"id":"module-3-isaac/vslam-and-depth","title":"4. VSLAM and Depth Perception","description":"Now that we have a GPU-accelerated perception pipeline, let's use it to give our robot two critical abilities: the ability to know where it is, and the ability to \"see\" in 3D.","source":"@site/docs/module-3-isaac/4-vslam-and-depth.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/vslam-and-depth","permalink":"/physical-ai-book/docs/module-3-isaac/vslam-and-depth","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-3-isaac/4-vslam-and-depth.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"4. VSLAM and Depth Perception","sidebar_label":"VSLAM and Depth","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS Perception","permalink":"/physical-ai-book/docs/module-3-isaac/isaac-ros-perception"},"next":{"title":"Nav2 Path Planning","permalink":"/physical-ai-book/docs/module-3-isaac/nav2-path-planning"}},{"id":"module-4-vla/cognitive-planning-pipelines","title":"4. Cognitive Planning Pipelines","description":"We now have the ability to translate voice commands into text using Whisper and to generate a sequence of abstract actions from an LLM (or our mock LLM). The next challenge is to build a Cognitive Planning Pipeline that takes this abstract action plan and translates it into concrete, executable ROS 2 commands for our robot.","source":"@site/docs/module-4-vla/4-cognitive-planning-pipelines.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/cognitive-planning-pipelines","permalink":"/physical-ai-book/docs/module-4-vla/cognitive-planning-pipelines","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-4-vla/4-cognitive-planning-pipelines.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"4. Cognitive Planning Pipelines","sidebar_label":"Cognitive Planning Pipelines","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"LLM to ROS Actions","permalink":"/physical-ai-book/docs/module-4-vla/llm-to-ros-actions"},"next":{"title":"Integrating VLA","permalink":"/physical-ai-book/docs/module-4-vla/integrating-vla"}},{"id":"module-4-vla/exercises","title":"6. Module 4 Exercises","description":"These exercises will challenge you to build and integrate the Vision-Language-Action (VLA) pipeline components we've discussed.","source":"@site/docs/module-4-vla/6-exercises.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/exercises","permalink":"/physical-ai-book/docs/module-4-vla/exercises","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-4-vla/6-exercises.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"title":"6. Module 4 Exercises","sidebar_label":"Exercises","sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Integrating VLA","permalink":"/physical-ai-book/docs/module-4-vla/integrating-vla"},"next":{"title":"Project Walkthrough","permalink":"/physical-ai-book/docs/capstone-project/project-walkthrough"}},{"id":"module-4-vla/integrating-vla","title":"5. Integrating Visual Perception into VLA","description":"Our VLA pipeline can now understand spoken language and translate it into a sequence of abstract actions. However, the actions currently rely on predefined locations (\"kitchen\", \"bedroom\") and abstract object names (\"mug\"). For true autonomy, our robot needs to visually perceive these objects and their locations in the real world.","source":"@site/docs/module-4-vla/5-integrating-vla.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/integrating-vla","permalink":"/physical-ai-book/docs/module-4-vla/integrating-vla","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-4-vla/5-integrating-vla.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"5. Integrating Visual Perception into VLA","sidebar_label":"Integrating VLA","sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Cognitive Planning Pipelines","permalink":"/physical-ai-book/docs/module-4-vla/cognitive-planning-pipelines"},"next":{"title":"Exercises","permalink":"/physical-ai-book/docs/module-4-vla/exercises"}},{"id":"module-4-vla/llm-to-ros-actions","title":"3. LLM to ROS Actions: The Cognitive Core","description":"We can now turn spoken commands into text. The next crucial step in our VLA pipeline is to convert this natural language text into a sequence of executable robot actions. This is the cognitive core of our robot's intelligence, typically handled by a Large Language Model (LLM).","source":"@site/docs/module-4-vla/3-llm-to-ros-actions.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/llm-to-ros-actions","permalink":"/physical-ai-book/docs/module-4-vla/llm-to-ros-actions","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-4-vla/3-llm-to-ros-actions.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"3. LLM to ROS Actions: The Cognitive Core","sidebar_label":"LLM to ROS Actions","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Whisper Voice Commands","permalink":"/physical-ai-book/docs/module-4-vla/whisper-voice-commands"},"next":{"title":"Cognitive Planning Pipelines","permalink":"/physical-ai-book/docs/module-4-vla/cognitive-planning-pipelines"}},{"id":"module-4-vla/vla-future-of-robotics","title":"1. VLA: The Future of Robotics","description":"So far, our robot has a nervous system (ROS 2), a physical body (URDF), a simulated world (Gazebo/Isaac Sim), and a brain that perceives its environment and plans paths (Isaac ROS/Nav2). What's missing? The ability to understand and execute high-level, human-like commands.","source":"@site/docs/module-4-vla/1-vla-future-of-robotics.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/vla-future-of-robotics","permalink":"/physical-ai-book/docs/module-4-vla/vla-future-of-robotics","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-4-vla/1-vla-future-of-robotics.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"1. VLA: The Future of Robotics","sidebar_label":"VLA Future of Robotics","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Exercises","permalink":"/physical-ai-book/docs/module-3-isaac/exercises"},"next":{"title":"Whisper Voice Commands","permalink":"/physical-ai-book/docs/module-4-vla/whisper-voice-commands"}},{"id":"module-4-vla/whisper-voice-commands","title":"2. Voice Commands with OpenAI Whisper","description":"The first step in any Vision-Language-Action (VLA) pipeline is often to convert human input into a format the robot can understand. For spoken commands, this means speech-to-text. In this chapter, we'll integrate OpenAI's powerful Whisper model into our ROS 2 system to enable our robot to understand voice commands.","source":"@site/docs/module-4-vla/2-whisper-voice-commands.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/whisper-voice-commands","permalink":"/physical-ai-book/docs/module-4-vla/whisper-voice-commands","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-4-vla/2-whisper-voice-commands.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"2. Voice Commands with OpenAI Whisper","sidebar_label":"Whisper Voice Commands","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"VLA Future of Robotics","permalink":"/physical-ai-book/docs/module-4-vla/vla-future-of-robotics"},"next":{"title":"LLM to ROS Actions","permalink":"/physical-ai-book/docs/module-4-vla/llm-to-ros-actions"}},{"id":"tutorial-basics/congratulations","title":"Congratulations!","description":"You have just learned the basics of Docusaurus and made some changes to the initial template.","source":"@site/docs/tutorial-basics/congratulations.md","sourceDirName":"tutorial-basics","slug":"/tutorial-basics/congratulations","permalink":"/physical-ai-book/docs/tutorial-basics/congratulations","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/tutorial-basics/congratulations.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6}},{"id":"tutorial-basics/create-a-blog-post","title":"Create a Blog Post","description":"Docusaurus creates a page for each blog post, but also a blog index page, a tag system, an RSS feed...","source":"@site/docs/tutorial-basics/create-a-blog-post.md","sourceDirName":"tutorial-basics","slug":"/tutorial-basics/create-a-blog-post","permalink":"/physical-ai-book/docs/tutorial-basics/create-a-blog-post","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/tutorial-basics/create-a-blog-post.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3}},{"id":"tutorial-basics/create-a-document","title":"Create a Document","description":"Documents are groups of pages connected through:","source":"@site/docs/tutorial-basics/create-a-document.md","sourceDirName":"tutorial-basics","slug":"/tutorial-basics/create-a-document","permalink":"/physical-ai-book/docs/tutorial-basics/create-a-document","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/tutorial-basics/create-a-document.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2}},{"id":"tutorial-basics/create-a-page","title":"Create a Page","description":"Add Markdown or React files to src/pages to create a standalone page:","source":"@site/docs/tutorial-basics/create-a-page.md","sourceDirName":"tutorial-basics","slug":"/tutorial-basics/create-a-page","permalink":"/physical-ai-book/docs/tutorial-basics/create-a-page","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/tutorial-basics/create-a-page.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1}},{"id":"tutorial-basics/deploy-your-site","title":"Deploy your site","description":"Docusaurus is a static-site-generator (also called Jamstack).","source":"@site/docs/tutorial-basics/deploy-your-site.md","sourceDirName":"tutorial-basics","slug":"/tutorial-basics/deploy-your-site","permalink":"/physical-ai-book/docs/tutorial-basics/deploy-your-site","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/tutorial-basics/deploy-your-site.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5}},{"id":"tutorial-basics/markdown-features","title":"Markdown Features","description":"Docusaurus supports Markdown and a few additional features.","source":"@site/docs/tutorial-basics/markdown-features.mdx","sourceDirName":"tutorial-basics","slug":"/tutorial-basics/markdown-features","permalink":"/physical-ai-book/docs/tutorial-basics/markdown-features","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/tutorial-basics/markdown-features.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4}},{"id":"tutorial-extras/manage-docs-versions","title":"Manage Docs Versions","description":"Docusaurus can manage multiple versions of your docs.","source":"@site/docs/tutorial-extras/manage-docs-versions.md","sourceDirName":"tutorial-extras","slug":"/tutorial-extras/manage-docs-versions","permalink":"/physical-ai-book/docs/tutorial-extras/manage-docs-versions","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/tutorial-extras/manage-docs-versions.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1}},{"id":"tutorial-extras/translate-your-site","title":"Translate your site","description":"Let's translate docs/intro.md to French.","source":"@site/docs/tutorial-extras/translate-your-site.md","sourceDirName":"tutorial-extras","slug":"/tutorial-extras/translate-your-site","permalink":"/physical-ai-book/docs/tutorial-extras/translate-your-site","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/tutorial-extras/translate-your-site.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro"},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"doc","id":"module-1-ros2/intro-to-ros2"},{"type":"doc","id":"module-1-ros2/nodes-topics-services"},{"type":"doc","id":"module-1-ros2/rclpy-for-control"},{"type":"doc","id":"module-1-ros2/humanoid-urdf-models"},{"type":"doc","id":"module-1-ros2/ai-agents-to-controllers"},{"type":"doc","id":"module-1-ros2/exercises"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"doc","id":"module-2-digital-twin/what-is-a-digital-twin"},{"type":"doc","id":"module-2-digital-twin/gazebo-physics"},{"type":"doc","id":"module-2-digital-twin/unity-for-hri"},{"type":"doc","id":"module-2-digital-twin/sensor-simulation"},{"type":"doc","id":"module-2-digital-twin/complete-humanoid-simulation"},{"type":"doc","id":"module-2-digital-twin/exercises"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac™)","items":[{"type":"doc","id":"module-3-isaac/intro-to-isaac"},{"type":"doc","id":"module-3-isaac/isaac-sim-photorealism"},{"type":"doc","id":"module-3-isaac/isaac-ros-perception"},{"type":"doc","id":"module-3-isaac/vslam-and-depth"},{"type":"doc","id":"module-3-isaac/nav2-path-planning"},{"type":"doc","id":"module-3-isaac/ai-controlled-humanoid-brain"},{"type":"doc","id":"module-3-isaac/exercises"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"doc","id":"module-4-vla/vla-future-of-robotics"},{"type":"doc","id":"module-4-vla/whisper-voice-commands"},{"type":"doc","id":"module-4-vla/llm-to-ros-actions"},{"type":"doc","id":"module-4-vla/cognitive-planning-pipelines"},{"type":"doc","id":"module-4-vla/integrating-vla"},{"type":"doc","id":"module-4-vla/exercises"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Capstone Project: The Autonomous Humanoid","items":[{"type":"doc","id":"capstone-project/project-walkthrough"}],"collapsed":true,"collapsible":true},{"type":"doc","id":"glossary"},{"type":"doc","id":"appendix"}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[{"id":"welcome","metadata":{"permalink":"/physical-ai-book/blog/welcome","editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/blog/2021-08-26-welcome/index.md","source":"@site/blog/2021-08-26-welcome/index.md","title":"Welcome","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","tags":[{"inline":false,"label":"Facebook","permalink":"/physical-ai-book/blog/tags/facebook","description":"Facebook tag description"},{"inline":false,"label":"Hello","permalink":"/physical-ai-book/blog/tags/hello","description":"Hello tag description"},{"inline":false,"label":"Docusaurus","permalink":"/physical-ai-book/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.56,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/physical-ai-book/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/physical-ai-book/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["slorber","yangshun"],"tags":["facebook","hello","docusaurus"]},"unlisted":false,"nextItem":{"title":"MDX Blog Post","permalink":"/physical-ai-book/blog/mdx-blog-post"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\n\nHere are a few tips you might find useful.\n\n<!-- truncate -->\n\nSimply add Markdown files (or folders) to the `blog` directory.\n\nRegular blog authors can be added to `authors.yml`.\n\nThe blog post date can be extracted from filenames, such as:\n\n- `2019-05-30-welcome.md`\n- `2019-05-30-welcome/index.md`\n\nA blog post folder can be convenient to co-locate blog post images:\n\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\n\nThe blog supports tags as well!\n\n**And if you don't want a blog**: just delete this directory, and use `blog: false` in your Docusaurus config."},{"id":"mdx-blog-post","metadata":{"permalink":"/physical-ai-book/blog/mdx-blog-post","editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/blog/2021-08-01-mdx-blog-post.mdx","source":"@site/blog/2021-08-01-mdx-blog-post.mdx","title":"MDX Blog Post","description":"Blog posts support Docusaurus Markdown features, such as MDX.","date":"2021-08-01T00:00:00.000Z","tags":[{"inline":false,"label":"Docusaurus","permalink":"/physical-ai-book/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.27,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/physical-ai-book/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}],"frontMatter":{"slug":"mdx-blog-post","title":"MDX Blog Post","authors":["slorber"],"tags":["docusaurus"]},"unlisted":false,"prevItem":{"title":"Welcome","permalink":"/physical-ai-book/blog/welcome"},"nextItem":{"title":"Long Blog Post","permalink":"/physical-ai-book/blog/long-blog-post"}},"content":"Blog posts support [Docusaurus Markdown features](https://docusaurus.io/docs/markdown-features), such as [MDX](https://mdxjs.com/).\n\n:::tip\n\nUse the power of React to create interactive blog posts.\n\n:::\n\n{/* truncate */}\n\nFor example, use JSX to create an interactive button:\n\n```js\n<button onClick={() => alert('button clicked!')}>Click me!</button>\n```\n\n<button onClick={() => alert('button clicked!')}>Click me!</button>"},{"id":"long-blog-post","metadata":{"permalink":"/physical-ai-book/blog/long-blog-post","editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/blog/2019-05-29-long-blog-post.md","source":"@site/blog/2019-05-29-long-blog-post.md","title":"Long Blog Post","description":"This is the summary of a very long blog post,","date":"2019-05-29T00:00:00.000Z","tags":[{"inline":false,"label":"Hello","permalink":"/physical-ai-book/blog/tags/hello","description":"Hello tag description"},{"inline":false,"label":"Docusaurus","permalink":"/physical-ai-book/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":2.04,"hasTruncateMarker":true,"authors":[{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/physical-ai-book/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"long-blog-post","title":"Long Blog Post","authors":"yangshun","tags":["hello","docusaurus"]},"unlisted":false,"prevItem":{"title":"MDX Blog Post","permalink":"/physical-ai-book/blog/mdx-blog-post"},"nextItem":{"title":"First Blog Post","permalink":"/physical-ai-book/blog/first-blog-post"}},"content":"This is the summary of a very long blog post,\n\nUse a `<!--` `truncate` `-->` comment to limit blog post size in the list view.\n\n<!-- truncate -->\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"},{"id":"first-blog-post","metadata":{"permalink":"/physical-ai-book/blog/first-blog-post","editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/blog/2019-05-28-first-blog-post.md","source":"@site/blog/2019-05-28-first-blog-post.md","title":"First Blog Post","description":"Lorem ipsum dolor sit amet...","date":"2019-05-28T00:00:00.000Z","tags":[{"inline":false,"label":"Hola","permalink":"/physical-ai-book/blog/tags/hola","description":"Hola tag description"},{"inline":false,"label":"Docusaurus","permalink":"/physical-ai-book/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.13,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/physical-ai-book/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/physical-ai-book/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"first-blog-post","title":"First Blog Post","authors":["slorber","yangshun"],"tags":["hola","docusaurus"]},"unlisted":false,"prevItem":{"title":"Long Blog Post","permalink":"/physical-ai-book/blog/long-blog-post"}},"content":"Lorem ipsum dolor sit amet...\n\n<!-- truncate -->\n\n...consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"}],"blogListPaginated":[{"items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"metadata":{"permalink":"/physical-ai-book/blog","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"blogTags":{"/physical-ai-book/blog/tags/facebook":{"inline":false,"label":"Facebook","permalink":"/physical-ai-book/blog/tags/facebook","description":"Facebook tag description","items":["welcome"],"pages":[{"items":["welcome"],"metadata":{"permalink":"/physical-ai-book/blog/tags/facebook","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/physical-ai-book/blog/tags/hello":{"inline":false,"label":"Hello","permalink":"/physical-ai-book/blog/tags/hello","description":"Hello tag description","items":["welcome","long-blog-post"],"pages":[{"items":["welcome","long-blog-post"],"metadata":{"permalink":"/physical-ai-book/blog/tags/hello","page":1,"postsPerPage":10,"totalPages":1,"totalCount":2,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/physical-ai-book/blog/tags/docusaurus":{"inline":false,"label":"Docusaurus","permalink":"/physical-ai-book/blog/tags/docusaurus","description":"Docusaurus tag description","items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"pages":[{"items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"metadata":{"permalink":"/physical-ai-book/blog/tags/docusaurus","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/physical-ai-book/blog/tags/hola":{"inline":false,"label":"Hola","permalink":"/physical-ai-book/blog/tags/hola","description":"Hola tag description","items":["first-blog-post"],"pages":[{"items":["first-blog-post"],"metadata":{"permalink":"/physical-ai-book/blog/tags/hola","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false}},"blogTagsListPath":"/physical-ai-book/blog/tags","authorsMap":{"yangshun":{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/physical-ai-book/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"},"slorber":{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/physical-ai-book/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}}}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/physical-ai-book/","source":"@site/src/pages/index.tsx"},{"type":"mdx","permalink":"/physical-ai-book/markdown-page","source":"@site/src/pages/markdown-page.md","title":"Markdown page example","description":"You don't need React to write simple standalone pages.","frontMatter":{"title":"Markdown page example"},"unlisted":false}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}
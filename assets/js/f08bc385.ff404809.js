"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[392],{5292(n,r,e){e.r(r),e.d(r,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module2/sensor-simulation","title":"Sensor Simulation for Humanoid Robots","description":"Sensor simulation is critical for humanoid robotics, as these robots rely on diverse sensors to perceive their environment, maintain balance, and execute complex tasks. This chapter covers the simulation of various sensor types essential for humanoid robot operation.","source":"@site/docs/module2/sensor-simulation.md","sourceDirName":"module2","slug":"/module2/sensor-simulation","permalink":"/docs/module2/sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/SyedZohaibTech/physical-ai-book/edit/main/docs/module2/sensor-simulation.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Sensor Simulation for Humanoid Robots"},"sidebar":"tutorialSidebar","previous":{"title":"Unity Rendering for Humanoid Perception","permalink":"/docs/module2/unity-rendering"},"next":{"title":"Introduction to NVIDIA Isaac","permalink":"/docs/module3/introduction"}}');var i=e(4848),t=e(8453);const o={sidebar_position:5,title:"Sensor Simulation for Humanoid Robots"},s="Sensor Simulation for Humanoid Robots",l={},c=[{value:"Overview of Humanoid Robot Sensors",id:"overview-of-humanoid-robot-sensors",level:2},{value:"1. Proprioceptive Sensors",id:"1-proprioceptive-sensors",level:3},{value:"2. Exteroceptive Sensors",id:"2-exteroceptive-sensors",level:3},{value:"3. Environmental Sensors",id:"3-environmental-sensors",level:3},{value:"Camera Simulation",id:"camera-simulation",level:2},{value:"1. RGB Camera Simulation",id:"1-rgb-camera-simulation",level:3},{value:"2. Depth Camera Simulation",id:"2-depth-camera-simulation",level:3},{value:"3. Stereo Camera Simulation",id:"3-stereo-camera-simulation",level:3},{value:"LIDAR Simulation",id:"lidar-simulation",level:2},{value:"1. 2D LIDAR",id:"1-2d-lidar",level:3},{value:"2. 3D LIDAR",id:"2-3d-lidar",level:3},{value:"IMU Simulation",id:"imu-simulation",level:2},{value:"Force/Torque Sensor Simulation",id:"forcetorque-sensor-simulation",level:2},{value:"Joint Position Sensors",id:"joint-position-sensors",level:2},{value:"Sensor Fusion in Simulation",id:"sensor-fusion-in-simulation",level:2},{value:"1. Kalman Filter Implementation",id:"1-kalman-filter-implementation",level:3},{value:"2. Extended Kalman Filter for Nonlinear Systems",id:"2-extended-kalman-filter-for-nonlinear-systems",level:3},{value:"Sensor Calibration and Validation",id:"sensor-calibration-and-validation",level:2},{value:"1. Calibration Procedures",id:"1-calibration-procedures",level:3},{value:"2. Validation Against Physical Sensors",id:"2-validation-against-physical-sensors",level:3},{value:"Advanced Sensor Simulation Techniques",id:"advanced-sensor-simulation-techniques",level:2},{value:"1. Domain Randomization",id:"1-domain-randomization",level:3},{value:"2. Sensor Failure Simulation",id:"2-sensor-failure-simulation",level:3}];function d(n){const r={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.header,{children:(0,i.jsx)(r.h1,{id:"sensor-simulation-for-humanoid-robots",children:"Sensor Simulation for Humanoid Robots"})}),"\n",(0,i.jsx)(r.p,{children:"Sensor simulation is critical for humanoid robotics, as these robots rely on diverse sensors to perceive their environment, maintain balance, and execute complex tasks. This chapter covers the simulation of various sensor types essential for humanoid robot operation."}),"\n",(0,i.jsx)(r.h2,{id:"overview-of-humanoid-robot-sensors",children:"Overview of Humanoid Robot Sensors"}),"\n",(0,i.jsx)(r.p,{children:"Humanoid robots typically employ a variety of sensors:"}),"\n",(0,i.jsx)(r.h3,{id:"1-proprioceptive-sensors",children:"1. Proprioceptive Sensors"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Joint position/velocity/effort sensors"}),"\n",(0,i.jsx)(r.li,{children:"IMUs for orientation and acceleration"}),"\n",(0,i.jsx)(r.li,{children:"Force/torque sensors at joints and feet"}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"2-exteroceptive-sensors",children:"2. Exteroceptive Sensors"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Cameras (RGB, depth, stereo)"}),"\n",(0,i.jsx)(r.li,{children:"LIDAR for 3D mapping"}),"\n",(0,i.jsx)(r.li,{children:"Tactile sensors for manipulation"}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"3-environmental-sensors",children:"3. Environmental Sensors"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Microphones for audio input"}),"\n",(0,i.jsx)(r.li,{children:"Temperature/humidity sensors"}),"\n",(0,i.jsx)(r.li,{children:"Proximity sensors"}),"\n"]}),"\n",(0,i.jsx)(r.h2,{id:"camera-simulation",children:"Camera Simulation"}),"\n",(0,i.jsx)(r.h3,{id:"1-rgb-camera-simulation",children:"1. RGB Camera Simulation"}),"\n",(0,i.jsx)(r.p,{children:"Simulating RGB cameras in Gazebo:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-xml",children:'<sensor name="camera" type="camera">\r\n  <camera name="head_camera">\r\n    <horizontal_fov>1.047</horizontal_fov>  \x3c!-- 60 degrees --\x3e\r\n    <image>\r\n      <width>640</width>\r\n      <height>480</height>\r\n      <format>R8G8B8</format>\r\n    </image>\r\n    <clip>\r\n      <near>0.1</near>\r\n      <far>10.0</far>\r\n    </clip>\r\n  </camera>\r\n  <always_on>1</always_on>\r\n  <update_rate>30</update_rate>\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(r.p,{children:"In Unity, implementing camera simulation:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class RGBCameraSimulator : MonoBehaviour\r\n{\r\n    [Header("Camera Settings")]\r\n    public int width = 640;\r\n    public int height = 480;\r\n    public float fieldOfView = 60f;\r\n    public float nearClip = 0.1f;\r\n    public float farClip = 10.0f;\r\n    \r\n    [Header("Noise Settings")]\r\n    public float noiseIntensity = 0.01f;\r\n    public float gamma = 1.0f;\r\n    \r\n    private Camera cam;\r\n    private RenderTexture renderTexture;\r\n    private Texture2D outputTexture;\r\n    \r\n    void Start()\r\n    {\r\n        SetupCamera();\r\n        CreateRenderTexture();\r\n    }\r\n    \r\n    void SetupCamera()\r\n    {\r\n        cam = GetComponent<Camera>();\r\n        cam.fieldOfView = fieldOfView;\r\n        cam.nearClipPlane = nearClip;\r\n        cam.farClipPlane = farClip;\r\n    }\r\n    \r\n    void CreateRenderTexture()\r\n    {\r\n        renderTexture = new RenderTexture(width, height, 24);\r\n        cam.targetTexture = renderTexture;\r\n        outputTexture = new Texture2D(width, height, TextureFormat.RGB24, false);\r\n    }\r\n    \r\n    void Update()\r\n    {\r\n        CaptureAndProcessImage();\r\n    }\r\n    \r\n    void CaptureAndProcessImage()\r\n    {\r\n        // Capture the camera image\r\n        RenderTexture.active = renderTexture;\r\n        outputTexture.ReadPixels(new Rect(0, 0, width, height), 0, 0);\r\n        outputTexture.Apply();\r\n        \r\n        // Apply noise simulation\r\n        ApplyNoiseToImage(outputTexture);\r\n        \r\n        // Apply gamma correction\r\n        ApplyGammaCorrection(outputTexture, gamma);\r\n        \r\n        RenderTexture.active = null;\r\n    }\r\n    \r\n    void ApplyNoiseToImage(Texture2D texture)\r\n    {\r\n        Color[] pixels = texture.GetPixels();\r\n        \r\n        for (int i = 0; i < pixels.Length; i++)\r\n        {\r\n            // Add Gaussian noise\r\n            float noise = Random.Range(-noiseIntensity, noiseIntensity);\r\n            pixels[i].r = Mathf.Clamp01(pixels[i].r + noise);\r\n            pixels[i].g = Mathf.Clamp01(pixels[i].g + noise);\r\n            pixels[i].b = Mathf.Clamp01(pixels[i].b + noise);\r\n        }\r\n        \r\n        texture.SetPixels(pixels);\r\n        texture.Apply();\r\n    }\r\n    \r\n    void ApplyGammaCorrection(Texture2D texture, float gamma)\r\n    {\r\n        Color[] pixels = texture.GetPixels();\r\n        \r\n        for (int i = 0; i < pixels.Length; i++)\r\n        {\r\n            pixels[i] = new Color(\r\n                Mathf.Pow(pixels[i].r, gamma),\r\n                Mathf.Pow(pixels[i].g, gamma),\r\n                Mathf.Pow(pixels[i].b, gamma)\r\n            );\r\n        }\r\n        \r\n        texture.SetPixels(pixels);\r\n        texture.Apply();\r\n    }\r\n    \r\n    // Method to get the processed image\r\n    public Texture2D GetImage()\r\n    {\r\n        return outputTexture;\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(r.h3,{id:"2-depth-camera-simulation",children:"2. Depth Camera Simulation"}),"\n",(0,i.jsx)(r.p,{children:"In Gazebo:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-xml",children:'<sensor name="depth_camera" type="depth">\r\n  <camera name="depth_head_camera">\r\n    <horizontal_fov>1.047</horizontal_fov>\r\n    <image>\r\n      <width>640</width>\r\n      <height>480</height>\r\n      <format>R_FLOAT32</format>\r\n    </image>\r\n    <clip>\r\n      <near>0.1</near>\r\n      <far>10.0</far>\r\n    </clip>\r\n  </camera>\r\n  <always_on>1</always_on>\r\n  <update_rate>30</update_rate>\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(r.h3,{id:"3-stereo-camera-simulation",children:"3. Stereo Camera Simulation"}),"\n",(0,i.jsx)(r.p,{children:"Stereo vision for depth perception:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-xml",children:'<sensor name="stereo_camera" type="multicamera">\r\n  <camera name="left_camera">\r\n    <horizontal_fov>1.047</horizontal_fov>\r\n    <image>\r\n      <width>640</width>\r\n      <height>480</height>\r\n      <format>R8G8B8</format>\r\n    </image>\r\n    <clip>\r\n      <near>0.1</near>\r\n      <far>10.0</far>\r\n    </clip>\r\n    <noise>\r\n      <type>gaussian</type>\r\n      <mean>0.0</mean>\r\n      <stddev>0.007</stddev>\r\n    </noise>\r\n  </camera>\r\n  <camera name="right_camera">\r\n    <horizontal_fov>1.047</horizontal_fov>\r\n    <image>\r\n      <width>640</width>\r\n      <height>480</height>\r\n      <format>R8G8B8</format>\r\n    </image>\r\n    <clip>\r\n      <near>0.1</near>\r\n      <far>10.0</far>\r\n    </clip>\r\n    <pose>0.1 0 0 0 0 0</pose>  \x3c!-- Baseline between cameras --\x3e\r\n    <noise>\r\n      <type>gaussian</type>\r\n      <mean>0.0</mean>\r\n      <stddev>0.007</stddev>\r\n    </noise>\r\n  </camera>\r\n  <always_on>1</always_on>\r\n  <update_rate>30</update_rate>\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(r.h2,{id:"lidar-simulation",children:"LIDAR Simulation"}),"\n",(0,i.jsx)(r.h3,{id:"1-2d-lidar",children:"1. 2D LIDAR"}),"\n",(0,i.jsx)(r.p,{children:"For navigation and obstacle detection:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-xml",children:'<sensor name="laser_scan" type="ray">\r\n  <ray>\r\n    <scan>\r\n      <horizontal>\r\n        <samples>720</samples>\r\n        <resolution>1</resolution>\r\n        <min_angle>-1.570796</min_angle>  \x3c!-- -90 degrees --\x3e\r\n        <max_angle>1.570796</max_angle>   \x3c!-- 90 degrees --\x3e\r\n      </horizontal>\r\n    </scan>\r\n    <range>\r\n      <min>0.1</min>\r\n      <max>10.0</max>\r\n      <resolution>0.01</resolution>\r\n    </range>\r\n  </ray>\r\n  <always_on>1</always_on>\r\n  <update_rate>10</update_rate>\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(r.h3,{id:"2-3d-lidar",children:"2. 3D LIDAR"}),"\n",(0,i.jsx)(r.p,{children:"For full 3D mapping and localization:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-xml",children:'<sensor name="3d_lidar" type="ray">\r\n  <ray>\r\n    <scan>\r\n      <horizontal>\r\n        <samples>1080</samples>\r\n        <resolution>1</resolution>\r\n        <min_angle>-3.14159</min_angle>  \x3c!-- -180 degrees --\x3e\r\n        <max_angle>3.14159</max_angle>   \x3c!-- 180 degrees --\x3e\r\n      </horizontal>\r\n      <vertical>\r\n        <samples>32</samples>\r\n        <resolution>1</resolution>\r\n        <min_angle>-0.5236</min_angle>  \x3c!-- -30 degrees --\x3e\r\n        <max_angle>0.3491</max_angle>   \x3c!-- 20 degrees --\x3e\r\n      </vertical>\r\n    </scan>\r\n    <range>\r\n      <min>0.1</min>\r\n      <max>30.0</max>\r\n      <resolution>0.01</resolution>\r\n    </range>\r\n  </ray>\r\n  <always_on>1</always_on>\r\n  <update_rate>10</update_rate>\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(r.h2,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,i.jsx)(r.p,{children:"IMUs are crucial for humanoid balance and orientation:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\r\n  <always_on>1</always_on>\r\n  <update_rate>100</update_rate>\r\n  <topic>__default_topic__</topic>\r\n  <visualize>false</visualize>\r\n  <imu>\r\n    <angular_velocity>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.0017</stddev>  \x3c!-- ~0.1 deg/s stddev --\x3e\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.0017</stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.0017</stddev>\r\n        </noise>\r\n      </z>\r\n    </angular_velocity>\r\n    <linear_acceleration>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>  \x3c!-- 0.017 m/s^2 stddev --\x3e\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n        </noise>\r\n      </z>\r\n    </linear_acceleration>\r\n  </imu>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(r.p,{children:"Unity implementation for IMU simulation:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class IMUSimulator : MonoBehaviour\r\n{\r\n    [Header("Noise Parameters")]\r\n    public float gyroNoise = 0.0017f;  // rad/s\r\n    public float accelNoise = 0.017f;  // m/s^2\r\n    \r\n    [Header("Bias Parameters")]\r\n    public Vector3 gyroBias = Vector3.zero;\r\n    public Vector3 accelBias = Vector3.zero;\r\n    \r\n    private float lastUpdate;\r\n    private Vector3 lastAngularVelocity;\r\n    private Vector3 lastLinearAcceleration;\r\n    \r\n    void Start()\r\n    {\r\n        lastUpdate = Time.time;\r\n        lastAngularVelocity = Vector3.zero;\r\n        lastLinearAcceleration = Physics.gravity;\r\n    }\r\n    \r\n    void Update()\r\n    {\r\n        float deltaTime = Time.time - lastUpdate;\r\n        lastUpdate = Time.time;\r\n        \r\n        // Calculate angular velocity (simplified)\r\n        Vector3 angularVelocity = CalculateAngularVelocity();\r\n        \r\n        // Calculate linear acceleration (simplified)\r\n        Vector3 linearAcceleration = CalculateLinearAcceleration();\r\n        \r\n        // Apply noise and bias\r\n        Vector3 noisyGyro = AddNoiseToGyro(angularVelocity);\r\n        Vector3 noisyAccel = AddNoiseToAccel(linearAcceleration);\r\n        \r\n        // Publish simulated IMU data\r\n        PublishIMUData(noisyGyro, noisyAccel, deltaTime);\r\n    }\r\n    \r\n    Vector3 CalculateAngularVelocity()\r\n    {\r\n        // In a real implementation, this would use physics engine data\r\n        // For simulation, we\'ll estimate based on rotation changes\r\n        return lastAngularVelocity;\r\n    }\r\n    \r\n    Vector3 CalculateLinearAcceleration()\r\n    {\r\n        // Calculate linear acceleration from physics\r\n        // This is a simplified approach\r\n        Vector3 currentVelocity = GetComponent<Rigidbody>().velocity;\r\n        Vector3 acceleration = (currentVelocity - lastLinearAcceleration) / Time.deltaTime;\r\n        lastLinearAcceleration = currentVelocity;\r\n        \r\n        // Remove gravity component\r\n        acceleration -= Physics.gravity;\r\n        \r\n        return acceleration;\r\n    }\r\n    \r\n    Vector3 AddNoiseToGyro(Vector3 gyroReading)\r\n    {\r\n        Vector3 noise = new Vector3(\r\n            Random.Range(-gyroNoise, gyroNoise),\r\n            Random.Range(-gyroNoise, gyroNoise),\r\n            Random.Range(-gyroNoise, gyroNoise)\r\n        );\r\n        \r\n        return gyroReading + noise + gyroBias;\r\n    }\r\n    \r\n    Vector3 AddNoiseToAccel(Vector3 accelReading)\r\n    {\r\n        Vector3 noise = new Vector3(\r\n            Random.Range(-accelNoise, accelNoise),\r\n            Random.Range(-accelNoise, accelNoise),\r\n            Random.Range(-accelNoise, accelNoise)\r\n        );\r\n        \r\n        return accelReading + noise + accelBias;\r\n    }\r\n    \r\n    void PublishIMUData(Vector3 gyro, Vector3 accel, float deltaTime)\r\n    {\r\n        // In a real implementation, this would publish to ROS\r\n        Debug.Log($"IMU: Gyro={gyro}, Accel={accel}");\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(r.h2,{id:"forcetorque-sensor-simulation",children:"Force/Torque Sensor Simulation"}),"\n",(0,i.jsx)(r.p,{children:"For humanoid robots, force/torque sensors at feet and hands are essential:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-xml",children:'<sensor name="left_foot_force_torque" type="force_torque">\r\n  <always_on>1</always_on>\r\n  <update_rate>100</update_rate>\r\n  <force_torque>\r\n    <frame>child</frame>\r\n    <measure_direction>child_to_parent</measure_direction>\r\n  </force_torque>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(r.h2,{id:"joint-position-sensors",children:"Joint Position Sensors"}),"\n",(0,i.jsx)(r.p,{children:"Simulating encoder feedback:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-xml",children:'<sensor name="joint_position_sensor" type="joint_position">\r\n  <joint_name>left_knee_joint</joint_name>\r\n  <always_on>1</always_on>\r\n  <update_rate>100</update_rate>\r\n  <topic>joint_position/left_knee</topic>\r\n  <noise>\r\n    <type>gaussian</type>\r\n    <mean>0.0</mean>\r\n    <stddev>0.001</stddev>  \x3c!-- 1 mrad noise --\x3e\r\n  </noise>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(r.h2,{id:"sensor-fusion-in-simulation",children:"Sensor Fusion in Simulation"}),"\n",(0,i.jsx)(r.h3,{id:"1-kalman-filter-implementation",children:"1. Kalman Filter Implementation"}),"\n",(0,i.jsx)(r.p,{children:"For sensor fusion in humanoid robots:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",children:"using UnityEngine;\r\nusing System;\r\n\r\npublic class KalmanFilter\r\n{\r\n    private Matrix4x4 state;           // State vector [position, velocity]\r\n    private Matrix4x4 covariance;      // Error covariance matrix\r\n    private Matrix4x4 processNoise;    // Process noise covariance\r\n    private Matrix4x4 measurementNoise; // Measurement noise covariance\r\n    private Matrix4x4 transition;      // State transition matrix\r\n    private Matrix4x4 observation;     // Observation matrix\r\n    \r\n    public KalmanFilter()\r\n    {\r\n        // Initialize with identity matrices\r\n        state = Matrix4x4.zero;\r\n        covariance = Matrix4x4.identity;\r\n        processNoise = Matrix4x4.identity * 0.1f;\r\n        measurementNoise = Matrix4x4.identity * 0.1f;\r\n        transition = Matrix4x4.identity;\r\n        observation = Matrix4x4.identity;\r\n        \r\n        // Set initial state and covariance\r\n        covariance[0, 0] = 1.0f; // Position uncertainty\r\n        covariance[1, 1] = 1.0f; // Velocity uncertainty\r\n    }\r\n    \r\n    public void Predict(float deltaTime)\r\n    {\r\n        // Update transition matrix based on time step\r\n        transition[0, 1] = deltaTime;\r\n        \r\n        // Predict state: x = F * x\r\n        state = transition * state;\r\n        \r\n        // Predict covariance: P = F * P * F^T + Q\r\n        Matrix4x4 Ft = Matrix4x4.transpose(transition);\r\n        covariance = transition * covariance * Ft + processNoise;\r\n    }\r\n    \r\n    public void Update(Vector2 measurement)\r\n    {\r\n        // Innovation: y = z - H * x\r\n        Vector2 innovation = measurement - GetObservation(state);\r\n        \r\n        // Innovation covariance: S = H * P * H^T + R\r\n        Matrix4x4 Ht = Matrix4x4.transpose(observation);\r\n        Matrix4x4 innovationCov = observation * covariance * Ht + measurementNoise;\r\n        \r\n        // Kalman gain: K = P * H^T * S^(-1)\r\n        Matrix4x4 kalmanGain = covariance * Ht * Matrix4x4.inverse(innovationCov);\r\n        \r\n        // Update state: x = x + K * y\r\n        state = state + (Matrix4x4)kalmanGain * (Matrix4x4)innovation;\r\n        \r\n        // Update covariance: P = (I - K * H) * P\r\n        Matrix4x4 I = Matrix4x4.identity;\r\n        covariance = (I - kalmanGain * observation) * covariance;\r\n    }\r\n    \r\n    private Vector2 GetObservation(Matrix4x4 stateMatrix)\r\n    {\r\n        return new Vector2(stateMatrix[0, 0], stateMatrix[1, 0]);\r\n    }\r\n    \r\n    public Vector2 GetState()\r\n    {\r\n        return new Vector2(state[0, 0], state[1, 0]);\r\n    }\r\n}\n"})}),"\n",(0,i.jsx)(r.h3,{id:"2-extended-kalman-filter-for-nonlinear-systems",children:"2. Extended Kalman Filter for Nonlinear Systems"}),"\n",(0,i.jsx)(r.p,{children:"For more complex sensor fusion:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",children:"using UnityEngine;\r\nusing System;\r\n\r\npublic class ExtendedKalmanFilter\r\n{\r\n    private Matrix4x4 state;\r\n    private Matrix4x4 covariance;\r\n    private Matrix4x4 processNoise;\r\n    private Matrix4x4 measurementNoise;\r\n    \r\n    public ExtendedKalmanFilter(int stateSize)\r\n    {\r\n        state = new Matrix4x4();\r\n        covariance = Matrix4x4.identity;\r\n        processNoise = Matrix4x4.identity * 0.1f;\r\n        measurementNoise = Matrix4x4.identity * 0.1f;\r\n    }\r\n    \r\n    public void Predict(System.Func<Matrix4x4, Matrix4x4> stateTransitionFunc,\r\n                        System.Func<Matrix4x4, Matrix4x4> jacobianFunc,\r\n                        float deltaTime)\r\n    {\r\n        // Nonlinear state prediction\r\n        Matrix4x4 predictedState = stateTransitionFunc(state);\r\n        \r\n        // Jacobian of state transition function\r\n        Matrix4x4 jacobian = jacobianFunc(state);\r\n        Matrix4x4 jacobianT = Matrix4x4.transpose(jacobian);\r\n        \r\n        // Predict covariance\r\n        covariance = jacobian * covariance * jacobianT + processNoise;\r\n        \r\n        // Update state\r\n        state = predictedState;\r\n    }\r\n    \r\n    public void Update(Vector2 measurement,\r\n                       System.Func<Matrix4x4, Vector2> observationFunc,\r\n                       System.Func<Matrix4x4, Matrix4x4> observationJacobianFunc)\r\n    {\r\n        // Predicted measurement\r\n        Vector2 predictedMeasurement = observationFunc(state);\r\n        \r\n        // Innovation\r\n        Vector2 innovation = measurement - predictedMeasurement;\r\n        \r\n        // Observation Jacobian\r\n        Matrix4x4 H = observationJacobianFunc(state);\r\n        Matrix4x4 Ht = Matrix4x4.transpose(H);\r\n        \r\n        // Innovation covariance\r\n        Matrix4x4 innovationCov = H * covariance * Ht + measurementNoise;\r\n        \r\n        // Kalman gain\r\n        Matrix4x4 kalmanGain = covariance * Ht * Matrix4x4.inverse(innovationCov);\r\n        \r\n        // Update state\r\n        state = state + (Matrix4x4)kalmanGain * (Matrix4x4)innovation;\r\n        \r\n        // Update covariance\r\n        Matrix4x4 I = Matrix4x4.identity;\r\n        covariance = (I - kalmanGain * H) * covariance;\r\n    }\r\n}\n"})}),"\n",(0,i.jsx)(r.h2,{id:"sensor-calibration-and-validation",children:"Sensor Calibration and Validation"}),"\n",(0,i.jsx)(r.h3,{id:"1-calibration-procedures",children:"1. Calibration Procedures"}),"\n",(0,i.jsx)(r.p,{children:"For accurate sensor simulation:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing System.Collections;\r\n\r\npublic class SensorCalibrator : MonoBehaviour\r\n{\r\n    public IMUSimulator imuSim;\r\n    public RGBCameraSimulator cameraSim;\r\n    \r\n    [Header("Calibration Settings")]\r\n    public int calibrationSamples = 1000;\r\n    public float calibrationDuration = 10.0f;\r\n    \r\n    private bool isCalibrating = false;\r\n    private int sampleCount = 0;\r\n    \r\n    public void StartCalibration()\r\n    {\r\n        if (!isCalibrating)\r\n        {\r\n            StartCoroutine(RunCalibration());\r\n        }\r\n    }\r\n    \r\n    IEnumerator RunCalibration()\r\n    {\r\n        isCalibrating = true;\r\n        sampleCount = 0;\r\n        \r\n        // Collect samples over time\r\n        float sampleInterval = calibrationDuration / calibrationSamples;\r\n        \r\n        while (sampleCount < calibrationSamples)\r\n        {\r\n            // Collect sensor data\r\n            CollectCalibrationSample();\r\n            \r\n            sampleCount++;\r\n            yield return new WaitForSeconds(sampleInterval);\r\n        }\r\n        \r\n        // Process collected data and update calibration\r\n        ProcessCalibrationData();\r\n        \r\n        isCalibrating = false;\r\n        Debug.Log("Calibration complete!");\r\n    }\r\n    \r\n    void CollectCalibrationSample()\r\n    {\r\n        // Collect IMU data for bias estimation\r\n        // Collect camera data for intrinsic/extrinsic calibration\r\n    }\r\n    \r\n    void ProcessCalibrationData()\r\n    {\r\n        // Process collected samples to estimate biases and parameters\r\n        // Update sensor models with calibrated values\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(r.h3,{id:"2-validation-against-physical-sensors",children:"2. Validation Against Physical Sensors"}),"\n",(0,i.jsx)(r.p,{children:"To ensure simulation accuracy:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing System.Collections.Generic;\r\n\r\npublic class SensorValidator : MonoBehaviour\r\n{\r\n    [Header("Validation Settings")]\r\n    public float tolerance = 0.1f;\r\n    \r\n    private List<float> simValues = new List<float>();\r\n    private List<float> realValues = new List<float>();\r\n    \r\n    public void AddSimulationValue(float value)\r\n    {\r\n        simValues.Add(value);\r\n    }\r\n    \r\n    public void AddRealValue(float value)\r\n    {\r\n        realValues.Add(value);\r\n    }\r\n    \r\n    public float CalculateRMSE()\r\n    {\r\n        if (simValues.Count != realValues.Count || simValues.Count == 0)\r\n            return float.PositiveInfinity;\r\n        \r\n        float sumSquaredErrors = 0.0f;\r\n        for (int i = 0; i < simValues.Count; i++)\r\n        {\r\n            float error = simValues[i] - realValues[i];\r\n            sumSquaredErrors += error * error;\r\n        }\r\n        \r\n        return Mathf.Sqrt(sumSquaredErrors / simValues.Count);\r\n    }\r\n    \r\n    public bool IsWithinTolerance()\r\n    {\r\n        return CalculateRMSE() <= tolerance;\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(r.h2,{id:"advanced-sensor-simulation-techniques",children:"Advanced Sensor Simulation Techniques"}),"\n",(0,i.jsx)(r.h3,{id:"1-domain-randomization",children:"1. Domain Randomization"}),"\n",(0,i.jsx)(r.p,{children:"To improve sim-to-real transfer:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class DomainRandomization : MonoBehaviour\r\n{\r\n    [Header("Lighting Randomization")]\r\n    public bool randomizeLighting = true;\r\n    public Color minLightColor = Color.white;\r\n    public Color maxLightColor = Color.white;\r\n    \r\n    [Header("Material Randomization")]\r\n    public bool randomizeMaterials = true;\r\n    public float minRoughness = 0.1f;\r\n    public float maxRoughness = 0.9f;\r\n    \r\n    [Header("Sensor Noise Randomization")]\r\n    public bool randomizeSensorNoise = true;\r\n    public float minNoise = 0.001f;\r\n    public float maxNoise = 0.01f;\r\n    \r\n    void Start()\r\n    {\r\n        if (randomizeLighting)\r\n            RandomizeLighting();\r\n        \r\n        if (randomizeMaterials)\r\n            RandomizeMaterials();\r\n        \r\n        if (randomizeSensorNoise)\r\n            RandomizeSensorNoise();\r\n    }\r\n    \r\n    void RandomizeLighting()\r\n    {\r\n        Light[] lights = FindObjectsOfType<Light>();\r\n        foreach (Light light in lights)\r\n        {\r\n            light.color = new Color(\r\n                Random.Range(minLightColor.r, maxLightColor.r),\r\n                Random.Range(minLightColor.g, maxLightColor.g),\r\n                Random.Range(minLightColor.b, maxLightColor.b)\r\n            );\r\n            \r\n            light.intensity = Random.Range(0.5f, 1.5f);\r\n        }\r\n    }\r\n    \r\n    void RandomizeMaterials()\r\n    {\r\n        Renderer[] renderers = FindObjectsOfType<Renderer>();\r\n        foreach (Renderer renderer in renderers)\r\n        {\r\n            Material material = renderer.material;\r\n            if (material.HasProperty("_Roughness"))\r\n            {\r\n                material.SetFloat("_Roughness", \r\n                    Random.Range(minRoughness, maxRoughness));\r\n            }\r\n        }\r\n    }\r\n    \r\n    void RandomizeSensorNoise()\r\n    {\r\n        // Randomize noise parameters for sensors\r\n        // This would typically be implemented in each sensor class\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(r.h3,{id:"2-sensor-failure-simulation",children:"2. Sensor Failure Simulation"}),"\n",(0,i.jsx)(r.p,{children:"For robustness testing:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class SensorFailureSimulator : MonoBehaviour\r\n{\r\n    [Header("Failure Parameters")]\r\n    public float failureProbability = 0.001f;  // Per frame\r\n    public float recoveryProbability = 0.1f;   // Per frame when failed\r\n    public float driftRate = 0.001f;           // Per frame when drifting\r\n    \r\n    private bool isFailed = false;\r\n    private bool isDrifting = false;\r\n    private float driftOffset = 0.0f;\r\n    \r\n    void Update()\r\n    {\r\n        if (!isFailed)\r\n        {\r\n            // Check for failure\r\n            if (Random.value < failureProbability)\r\n            {\r\n                isFailed = true;\r\n                Debug.Log("Sensor failure simulated!");\r\n            }\r\n        }\r\n        else\r\n        {\r\n            // Check for recovery\r\n            if (Random.value < recoveryProbability)\r\n            {\r\n                isFailed = false;\r\n                isDrifting = false;\r\n                driftOffset = 0.0f;\r\n                Debug.Log("Sensor recovered!");\r\n            }\r\n            else if (Random.value < 0.01f) // Low probability of drift\r\n            {\r\n                isDrifting = true;\r\n            }\r\n        }\r\n        \r\n        if (isDrifting)\r\n        {\r\n            driftOffset += Random.Range(-driftRate, driftRate);\r\n        }\r\n    }\r\n    \r\n    public float ApplyFailureToValue(float value)\r\n    {\r\n        if (isFailed)\r\n        {\r\n            // Return a failure value (e.g., zero or NaN)\r\n            return 0.0f;  // Or float.NaN for more realistic failure\r\n        }\r\n        \r\n        // Apply drift if applicable\r\n        return value + driftOffset;\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(r.p,{children:"Accurate sensor simulation is fundamental to developing robust humanoid robots. By properly modeling sensor characteristics, noise, and failure modes, developers can create more reliable and transferable robot behaviors that will perform well in real-world scenarios."})]})}function u(n={}){const{wrapper:r}={...(0,t.R)(),...n.components};return r?(0,i.jsx)(r,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},8453(n,r,e){e.d(r,{R:()=>o,x:()=>s});var a=e(6540);const i={},t=a.createContext(i);function o(n){const r=a.useContext(t);return a.useMemo(function(){return"function"==typeof n?n(r):{...r,...n}},[r,n])}function s(n){let r;return r=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:o(n.components),a.createElement(t.Provider,{value:r},n.children)}}}]);
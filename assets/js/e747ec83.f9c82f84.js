"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[7051],{3583:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"glossary","title":"Glossary","description":"This glossary provides definitions for key terms and acronyms used throughout the \\"Physical AI & Humanoid Robotics\\" textbook.","source":"@site/docs/glossary.md","sourceDirName":".","slug":"/glossary","permalink":"/physical-ai-book/docs/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/glossary.md","tags":[],"version":"current","sidebarPosition":100,"frontMatter":{"title":"Glossary","sidebar_position":100},"sidebar":"tutorialSidebar","previous":{"title":"Project Walkthrough","permalink":"/physical-ai-book/docs/capstone-project/project-walkthrough"},"next":{"title":"Appendix","permalink":"/physical-ai-book/docs/appendix"}}');var t=s(4848),o=s(8453);const r={title:"Glossary",sidebar_position:100},a="Glossary of Terms",l={},c=[{value:"A",id:"a",level:2},{value:"C",id:"c",level:2},{value:"D",id:"d",level:2},{value:"G",id:"g",level:2},{value:"H",id:"h",level:2},{value:"I",id:"i",level:2},{value:"J",id:"j",level:2},{value:"L",id:"l",level:2},{value:"M",id:"m",level:2},{value:"N",id:"n",level:2},{value:"P",id:"p",level:2},{value:"R",id:"r",level:2},{value:"S",id:"s",level:2},{value:"T",id:"t",level:2},{value:"U",id:"u",level:2},{value:"V",id:"v",level:2},{value:"W",id:"w",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",strong:"strong",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"glossary-of-terms",children:"Glossary of Terms"})}),"\n",(0,t.jsx)(n.p,{children:'This glossary provides definitions for key terms and acronyms used throughout the "Physical AI & Humanoid Robotics" textbook.'}),"\n",(0,t.jsx)(n.h2,{id:"a",children:"A"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Action (ROS 2)"}),": A type of ROS 2 communication for long-running, goal-oriented tasks that provide feedback during execution and a final result upon completion. Consists of a goal, result, and feedback."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"AI (Artificial Intelligence)"}),": The simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, and self-correction."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"AI Agent"}),": An autonomous entity that observes through sensors and acts upon an environment using actuators. In robotics, often refers to software that makes decisions for a robot."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"AMENT"}),": The build system used by ROS 2. It is a set of tools to compile and link packages."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"API (Application Programming Interface)"}),": A set of defined methods of communication among various components."]}),"\n",(0,t.jsx)(n.h2,{id:"c",children:"C"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Colcon"}),": The build tool used in ROS 2. It orchestrates the compilation of multiple packages in a workspace."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Cognitive Planning"}),": The process by which an intelligent agent (often using an LLM) breaks down high-level goals into a sequence of executable sub-tasks, reasoning about the environment and available actions."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Controller (ROS 2)"}),": A software component that manages a robot's joints or actuators to achieve a desired state (e.g., position, velocity, effort)."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Costmap (Nav2)"}),": A 2D grid used by the Nav2 stack to represent the robot's environment, indicating traversability and obstacles for path planning."]}),"\n",(0,t.jsx)(n.h2,{id:"d",children:"D"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Depth Camera"}),": A sensor that captures an image where each pixel's value represents its distance from the camera, providing 3D spatial information."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Digital Twin"}),": A virtual, physics-based, 1:1 representation of a physical object or system, connected to the same control software as its real-world counterpart."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Docusaurus"}),": A static site generator that helps you build optimized websites quickly. Used for building this textbook."]}),"\n",(0,t.jsx)(n.h2,{id:"g",children:"G"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Gazebo"}),": A powerful open-source 3D robotics simulator, known for its high-fidelity physics engine."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"GPU (Graphics Processing Unit)"}),": A specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer for output to a display device. Essential for AI and robotics."]}),"\n",(0,t.jsx)(n.h2,{id:"h",children:"H"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Human-Robot Interaction (HRI)"}),": The study of interactions between humans and robots."]}),"\n",(0,t.jsx)(n.h2,{id:"i",children:"I"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"IMU (Inertial Measurement Unit)"}),": An electronic device that measures and reports a body's specific force, angular rate, and sometimes the magnetic field surrounding the body, using a combination of accelerometers, gyroscopes, and magnetometers."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Isaac ROS"}),": NVIDIA's collection of hardware-accelerated ROS 2 packages (GEMs) that leverage GPUs for performance-critical robotics tasks like perception and navigation."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Isaac Sim"}),": NVIDIA's robotics simulation application, built on Omniverse, focused on photorealistic rendering and physics simulation for AI training and development."]}),"\n",(0,t.jsx)(n.h2,{id:"j",children:"J"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Joint (URDF)"}),": Defines the connection and relative motion between two links in a robot model (e.g., revolute, prismatic, fixed)."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"JointState (ROS 2 Message)"}),": A standard ROS 2 message type (",(0,t.jsx)(n.code,{children:"sensor_msgs/msg/JointState"}),") used to convey the current state (position, velocity, effort) of a robot's joints."]}),"\n",(0,t.jsx)(n.h2,{id:"l",children:"L"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Launch File (ROS 2)"}),": A Python script used to automate the startup of multiple ROS 2 nodes, programs, and configurations with a single command."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"LiDAR (Light Detection and Ranging)"}),": A remote sensing method that uses light in the form of a pulsed laser to measure ranges (variable distances) to the Earth. In robotics, used for mapping and obstacle detection."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Link (URDF)"}),": Represents a rigid part of a robot model in a URDF file, describing its visual, collision, and inertial properties."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"LLM (Large Language Model)"}),": A type of artificial intelligence program that can generate and understand human-like language, often used for tasks like text generation, translation, and reasoning."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Localization"}),": The process by which a robot determines its own position and orientation within a known map."]}),"\n",(0,t.jsx)(n.h2,{id:"m",children:"M"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Mapping"}),": The process by which a robot builds a representation (a map) of its environment."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Message (ROS 2)"}),": A data structure used for communication between ROS 2 nodes over topics."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Middleware"}),": Software that provides common services and capabilities to applications beyond those offered by the operating system. ROS is a robotics middleware."]}),"\n",(0,t.jsx)(n.h2,{id:"n",children:"N"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Nav2 (Navigation2)"}),": The ROS 2 navigation stack, providing functionalities for autonomous movement, including global and local path planning, and obstacle avoidance."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"NITROS (NVIDIA Isaac Transport for ROS)"}),": A technology in Isaac ROS that enables high-performance, zero-copy data transfer between CPU and GPU for ROS 2 messages."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Node (ROS 2)"}),": The smallest executable unit in a ROS 2 system, responsible for a specific task (e.g., a camera driver node, a motor controller node)."]}),"\n",(0,t.jsx)(n.h2,{id:"p",children:"P"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Perception"}),": The process by which a robot interprets sensory data (from cameras, LiDAR, etc.) to understand its environment."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Point Cloud"}),": A set of data points in a three-dimensional coordinate system, typically generated by 3D scanners (e.g., LiDAR, depth cameras), representing the external surface of an object or environment."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Prompt Engineering"}),": The process of designing and refining input prompts for large language models to elicit desired outputs."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Publish/Subscribe"}),": A messaging pattern where senders (publishers) do not program messages to be sent directly to specific receivers (subscribers), but instead characterize published messages into classes without knowledge of which subscribers, if any, there may be."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Pytest"}),": A popular Python testing framework used for writing unit and integration tests."]}),"\n",(0,t.jsx)(n.h2,{id:"r",children:"R"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"rclpy"}),": The official Python client library for ROS 2, used to write ROS 2 nodes in Python."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Request/Response"}),": A communication pattern where a client sends a request to a server, and the server processes the request and sends a response back to the client. Used in ROS 2 Services."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ROS (Robot Operating System)"}),": An open-source robotics middleware suite that provides libraries and tools to help software developers create robot applications."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ROS 2"}),": The next generation of ROS, designed with improved real-time capabilities, security, and multi-robot support."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ros2_control"}),": A generic framework for robot control in ROS 2, providing a standardized interface for hardware abstraction and controller management."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ROS-TCP-Connector"}),": A plugin for Unity that enables communication between a Unity simulation and a ROS 2 network over TCP."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"RViz"}),": A 3D visualization tool for ROS, allowing users to view sensor data, robot models, and navigation trajectories."]}),"\n",(0,t.jsx)(n.h2,{id:"s",children:"S"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"SDF (Simulation Description Format)"}),": An XML format used by Gazebo to describe robots, environments, and other simulation elements. An extension of URDF."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"SLAM (Simultaneous Localization and Mapping)"}),": The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Service (ROS 2)"}),": A type of ROS 2 communication for one-shot, request-response interactions between nodes."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Speech-to-Text"}),": The process of converting spoken words into written text."]}),"\n",(0,t.jsx)(n.h2,{id:"t",children:"T"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"TF2 (Transformations)"}),": A ROS 2 library that keeps track of coordinate frames over time, allowing easy transformation of data between different frames (e.g., robot base, camera, world)."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Topic (ROS 2)"}),": A named bus over which ROS 2 nodes exchange messages using a publish/subscribe mechanism."]}),"\n",(0,t.jsx)(n.h2,{id:"u",children:"U"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Unity"}),": A popular real-time 3D development platform (game engine) increasingly used for high-fidelity robotics simulation and synthetic data generation."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"URDF (Unified Robot Description Format)"}),": An XML file format used in ROS to describe the physical and kinematic properties of a robot."]}),"\n",(0,t.jsx)(n.h2,{id:"v",children:"V"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"VLA (Vision-Language-Action)"}),": A robotics paradigm that combines visual perception, natural language understanding (often with LLMs), and robot action execution to enable robots to perform complex tasks based on high-level human commands."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"VSLAM (Visual SLAM)"}),": A type of SLAM that uses one or more cameras as its primary sensor for simultaneous localization and mapping."]}),"\n",(0,t.jsx)(n.h2,{id:"w",children:"W"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Whisper (OpenAI)"}),": A general-purpose speech recognition model by OpenAI, capable of transcribing speech into text with high accuracy."]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>a});var i=s(6540);const t={},o=i.createContext(t);function r(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);
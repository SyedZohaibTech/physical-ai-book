"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[5003],{8453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>r});var o=t(6540);const i={},s=o.createContext(i);function l(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),o.createElement(s.Provider,{value:n},e.children)}},9417:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"capstone-project/project-walkthrough","title":"1. Capstone Project Walkthrough","description":"Congratulations on making it to the Capstone Project! This is where you\'ll bring together all the knowledge and skills you\'ve gained throughout the textbook to build a fully autonomous humanoid assistant in a simulated environment.","source":"@site/docs/capstone-project/1-project-walkthrough.md","sourceDirName":"capstone-project","slug":"/capstone-project/project-walkthrough","permalink":"/physical-ai-book/docs/capstone-project/project-walkthrough","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/capstone-project/1-project-walkthrough.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"1. Capstone Project Walkthrough","sidebar_label":"Project Walkthrough","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Exercises","permalink":"/physical-ai-book/docs/module-4-vla/exercises"},"next":{"title":"Glossary","permalink":"/physical-ai-book/docs/glossary"}}');var i=t(4848),s=t(8453);const l={title:"1. Capstone Project Walkthrough",sidebar_label:"Project Walkthrough",sidebar_position:1},r="1. Capstone Project: The Autonomous Humanoid Assistant",a={},c=[{value:"Project Overview",id:"project-overview",level:2},{value:"System Architecture",id:"system-architecture",level:2},{value:"Component Breakdown:",id:"component-breakdown",level:3},{value:"High-Level Setup Guide",id:"high-level-setup-guide",level:2},{value:"1. Environment Setup",id:"1-environment-setup",level:3},{value:"2. Robot Description (URDF/SDF)",id:"2-robot-description-urdfsdf",level:3},{value:"3. Simulation Launch File",id:"3-simulation-launch-file",level:3},{value:"4. Running the Project",id:"4-running-the-project",level:3},{value:"5. Interacting with the Robot",id:"5-interacting-with-the-robot",level:3},{value:"Evaluation Rubric",id:"evaluation-rubric",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"1-capstone-project-the-autonomous-humanoid-assistant",children:"1. Capstone Project: The Autonomous Humanoid Assistant"})}),"\n",(0,i.jsx)(n.p,{children:"Congratulations on making it to the Capstone Project! This is where you'll bring together all the knowledge and skills you've gained throughout the textbook to build a fully autonomous humanoid assistant in a simulated environment."}),"\n",(0,i.jsx)(n.p,{children:"Your goal is to create a robot that can:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Understand voice commands"})," for high-level tasks."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Perceive its environment"})," to locate objects and navigate."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Plan and execute a sequence of actions"})," to fulfill the commands."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Navigate autonomously"})," to target locations."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Simulate basic manipulation"})," of objects."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"project-overview",children:"Project Overview"}),"\n",(0,i.jsx)(n.p,{children:"You will be tasked with integrating the ROS 2 fundamentals from Module 1, the simulation capabilities of Module 2, the AI perception and planning tools of Module 3, and the Vision-Language-Action pipelines of Module 4."}),"\n",(0,i.jsx)(n.p,{children:'The project will culminate in a simulated humanoid robot that can respond to a voice command like "Go to the table, pick up the blue ball, and bring it to me."'}),"\n",(0,i.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,i.jsx)(n.p,{children:"The following diagram illustrates the complete system architecture for your autonomous humanoid assistant. You will be implementing and integrating each of these components."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    subgraph Human Interface\n        A[Microphone Input] --\x3e B(Whisper Node);\n        B -- /voice_command (String) --\x3e C(Action Executor);\n    end\n\n    subgraph Cognitive & Planning Layer\n        C -- Calls LLM Service --\x3e D(Mock LLM Planner Service);\n        D -- Action Plan (List of Strings) --\x3e C;\n        C -- Object Lookup --\x3e E{Object Database};\n        E -- Object Pose --\x3e C;\n        C -- Goals (NavigateToPose) --\x3e F(Nav2 Stack);\n        C -- Commands (FollowJointTrajectory) --\x3e G(ROS2 Control);\n    end\n\n    subgraph Perception Layer\n        H[Simulated Camera & Depth Sensor] --\x3e I(Isaac ROS Perception Nodes);\n        I -- /tf, /scan, /detected_objects --\x3e E & F;\n    end\n\n    subgraph Low-Level Control & Simulation\n        F -- /cmd_vel (Twist) --\x3e J(Humanoid Locomotion Controller);\n        J -- Joint Trajectories --\x3e G;\n        G -- Joint Commands --\x3e K(Isaac Sim / Gazebo Robot Model);\n        K -- State Feedback & Sensor Data --\x3e H;\n    end\n"})}),"\n",(0,i.jsx)(n.h3,{id:"component-breakdown",children:"Component Breakdown:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Whisper Node"}),": Transcribes spoken commands into text and publishes them to the ",(0,i.jsx)(n.code,{children:"/voice_command"})," topic."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mock LLM Planner Service"}),": Translates the text command into a sequence of abstract actions (e.g., ",(0,i.jsx)(n.code,{children:"navigate_to(location)"}),", ",(0,i.jsx)(n.code,{children:"pick_up(object)"}),")."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Object Database"}),": Stores the real-time 3D poses of detected objects, populated by the perception nodes."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Perception Nodes"}),": Process simulated sensor data (stereo images, depth images, IMU) to provide visual SLAM (localization and mapping), 2D laser scans, and 3D object detection."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Nav2 Stack"}),": Takes navigation goals and produces velocity commands, avoiding obstacles using the perception data."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Humanoid Locomotion Controller"}),": Translates Nav2's velocity commands into specific joint trajectories for the humanoid's bipedal movement."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 Control"}),": Manages the low-level joint control of the humanoid robot in the simulation."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Action Executor"}),": The central orchestrator. It subscribes to voice commands, calls the LLM, queries the object database, and executes the planned actions by interacting with Nav2 and ROS 2 Control."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac Sim / Gazebo Robot Model"}),": The simulated humanoid robot, environment, and sensors."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"high-level-setup-guide",children:"High-Level Setup Guide"}),"\n",(0,i.jsx)(n.h3,{id:"1-environment-setup",children:"1. Environment Setup"}),"\n",(0,i.jsx)(n.p,{children:"Ensure you have:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ubuntu 22.04 LTS."}),"\n",(0,i.jsx)(n.li,{children:"ROS 2 Humble Hawksbill installed and sourced."}),"\n",(0,i.jsxs)(n.li,{children:["A working ",(0,i.jsx)(n.code,{children:"colcon"})," workspace (",(0,i.jsx)(n.code,{children:"~/ros2_ws"}),")."]}),"\n",(0,i.jsxs)(n.li,{children:["Your ",(0,i.jsx)(n.code,{children:"py_pubsub"}),", ",(0,i.jsx)(n.code,{children:"llm_planner_pkg"}),", ",(0,i.jsx)(n.code,{children:"action_executor_pkg"})," packages in ",(0,i.jsx)(n.code,{children:"~/ros2_ws/src/"})," and built."]}),"\n",(0,i.jsx)(n.li,{children:"Isaac Sim installed with Isaac ROS configured (if using Isaac Sim for simulation)."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"2-robot-description-urdfsdf",children:"2. Robot Description (URDF/SDF)"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Use your humanoid robot's URDF/SDF model, ensuring it has all necessary ",(0,i.jsx)(n.code,{children:"<visual>"}),", ",(0,i.jsx)(n.code,{children:"<collision>"}),", and ",(0,i.jsx)(n.code,{children:"<inertial>"})," tags."]}),"\n",(0,i.jsxs)(n.li,{children:["Ensure it includes Gazebo/Isaac Sim plugins for ",(0,i.jsx)(n.code,{children:"ros2_control"})," and sensors (camera, depth sensor, IMU)."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"3-simulation-launch-file",children:"3. Simulation Launch File"}),"\n",(0,i.jsxs)(n.p,{children:["Create a main launch file (",(0,i.jsx)(n.code,{children:"capstone_launch.py"}),") in a new package (e.g., ",(0,i.jsx)(n.code,{children:"humanoid_capstone_pkg"}),") that starts:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Your chosen simulator (Isaac Sim or Gazebo) with your humanoid robot loaded."}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"robot_state_publisher"})}),"\n",(0,i.jsxs)(n.li,{children:["All necessary ",(0,i.jsx)(n.code,{children:"ros2_control"})," controllers (joint state broadcaster, joint trajectory controller)."]}),"\n",(0,i.jsx)(n.li,{children:"Your Isaac ROS perception nodes (VSLAM, depth image processing)."}),"\n",(0,i.jsx)(n.li,{children:"The full Nav2 stack, configured with the correct topics from your perception nodes."}),"\n",(0,i.jsxs)(n.li,{children:["Your ",(0,i.jsx)(n.code,{children:"whisper_node"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Your ",(0,i.jsx)(n.code,{children:"mock_llm_planner"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Your ",(0,i.jsx)(n.code,{children:"action_executor"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"RViz for visualization."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"4-running-the-project",children:"4. Running the Project"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Open a terminal, navigate to your workspace, and source it:","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws\nsource install/setup.bash\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Launch your capstone project:","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch humanoid_capstone_pkg capstone_launch.py\n"})}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Open RViz and configure it to visualize the map, robot model, point clouds, and path plans."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"5-interacting-with-the-robot",children:"5. Interacting with the Robot"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Speak commands into your microphone."}),"\n",(0,i.jsx)(n.li,{children:"Observe the robot's behavior in the simulation and its internal state in RViz."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"evaluation-rubric",children:"Evaluation Rubric"}),"\n",(0,i.jsx)(n.p,{children:"Your Capstone Project will be evaluated based on the following criteria:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Criterion"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Exceeds Expectations (100%)"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Meets Expectations (75%)"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Needs Improvement (50%)"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"System Integration"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"All components (Whisper, LLM, Perception, Nav2, Control) work seamlessly together."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Most components are integrated, minor issues remain."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Significant integration gaps, core functionality broken."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Functionality"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:'Robot reliably executes complex multi-step voice commands (e.g., navigate, perceive, "manipulate").'}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Robot executes basic voice commands, some multi-step tasks fail."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Robot responds to few commands or fails often."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Code Quality & Clarity"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Clean, well-commented, modular code. Clear ROS 2 package structure."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Code is functional but may lack comments or optimal structure."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Code is difficult to understand or poorly organized."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Documentation & Explanation"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Detailed README for the capstone package. Clear explanation of design choices."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Basic README and explanation."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Missing or unclear documentation."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Demonstration"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Fluent demonstration of robot performing tasks in simulation."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Demonstrates basic tasks, some errors encountered."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Struggles to demonstrate basic functionality."})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"This Capstone Project is your opportunity to synthesize everything you've learned. Good luck, and have fun building your autonomous humanoid!"})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);
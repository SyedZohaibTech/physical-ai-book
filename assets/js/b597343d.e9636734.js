"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[868],{4822(e,n,r){r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module2/unity-rendering","title":"Unity Rendering for Humanoid Perception","description":"Unity\'s advanced rendering capabilities provide high-fidelity visual simulation essential for humanoid robot perception systems. This chapter explores how to leverage Unity\'s rendering pipeline to create photorealistic environments that support computer vision and perception algorithm development.","source":"@site/docs/module2/unity-rendering.md","sourceDirName":"module2","slug":"/module2/unity-rendering","permalink":"/docs/module2/unity-rendering","draft":false,"unlisted":false,"editUrl":"https://github.com/SyedZohaibTech/physical-ai-book/edit/main/docs/module2/unity-rendering.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Unity Rendering for Humanoid Perception"},"sidebar":"tutorialSidebar","previous":{"title":"Physics Simulation for Humanoid Robots","permalink":"/docs/module2/physics-simulation"},"next":{"title":"Sensor Simulation for Humanoid Robots","permalink":"/docs/module2/sensor-simulation"}}');var t=r(4848),a=r(8453);const o={sidebar_position:4,title:"Unity Rendering for Humanoid Perception"},s="Unity Rendering for Humanoid Perception",l={},d=[{value:"Unity for Robotics Overview",id:"unity-for-robotics-overview",level:2},{value:"Setting Up Unity for Robotics",id:"setting-up-unity-for-robotics",level:2},{value:"1. Installing Unity Robotics Package",id:"1-installing-unity-robotics-package",level:3},{value:"2. Project Configuration",id:"2-project-configuration",level:3},{value:"High-Fidelity Visual Rendering",id:"high-fidelity-visual-rendering",level:2},{value:"1. Lighting Systems",id:"1-lighting-systems",level:3},{value:"Real-time Global Illumination",id:"real-time-global-illumination",level:4},{value:"Light Probes for Dynamic Objects",id:"light-probes-for-dynamic-objects",level:4},{value:"2. Material and Texture Systems",id:"2-material-and-texture-systems",level:3},{value:"3. Shader Considerations",id:"3-shader-considerations",level:3},{value:"Perception-Specific Rendering Features",id:"perception-specific-rendering-features",level:2},{value:"1. Camera Systems",id:"1-camera-systems",level:3},{value:"RGB Cameras",id:"rgb-cameras",level:4},{value:"Depth Cameras",id:"depth-cameras",level:4},{value:"2. Sensor Simulation Pipeline",id:"2-sensor-simulation-pipeline",level:3},{value:"Environment Creation for Perception Tasks",id:"environment-creation-for-perception-tasks",level:2},{value:"1. Indoor Environments",id:"1-indoor-environments",level:3},{value:"2. Outdoor Environments",id:"2-outdoor-environments",level:3},{value:"Rendering Optimization for Real-time Performance",id:"rendering-optimization-for-real-time-performance",level:2},{value:"1. Level of Detail (LOD)",id:"1-level-of-detail-lod",level:3},{value:"2. Occlusion Culling",id:"2-occlusion-culling",level:3},{value:"3. Shader Optimization",id:"3-shader-optimization",level:3},{value:"Integration with ROS/ROS 2",id:"integration-with-rosros-2",level:2},{value:"1. ROS# Integration",id:"1-ros-integration",level:3},{value:"2. Sensor Data Publishing",id:"2-sensor-data-publishing",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"1. Frame Rate Optimization",id:"1-frame-rate-optimization",level:3},{value:"2. Memory Management",id:"2-memory-management",level:3},{value:"3. Multi-threading",id:"3-multi-threading",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"unity-rendering-for-humanoid-perception",children:"Unity Rendering for Humanoid Perception"})}),"\n",(0,t.jsx)(n.p,{children:"Unity's advanced rendering capabilities provide high-fidelity visual simulation essential for humanoid robot perception systems. This chapter explores how to leverage Unity's rendering pipeline to create photorealistic environments that support computer vision and perception algorithm development."}),"\n",(0,t.jsx)(n.h2,{id:"unity-for-robotics-overview",children:"Unity for Robotics Overview"}),"\n",(0,t.jsx)(n.p,{children:"Unity has emerged as a powerful platform for robotics simulation, particularly for perception tasks. Unlike physics-focused simulators like Gazebo, Unity excels at:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Photorealistic rendering"}),"\n",(0,t.jsx)(n.li,{children:"Complex lighting scenarios"}),"\n",(0,t.jsx)(n.li,{children:"High-quality textures and materials"}),"\n",(0,t.jsx)(n.li,{children:"Realistic environmental effects"}),"\n",(0,t.jsx)(n.li,{children:"VR/AR integration"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"For humanoid robots, Unity is particularly valuable for developing perception systems that must operate in real-world environments."}),"\n",(0,t.jsx)(n.h2,{id:"setting-up-unity-for-robotics",children:"Setting Up Unity for Robotics"}),"\n",(0,t.jsx)(n.h3,{id:"1-installing-unity-robotics-package",children:"1. Installing Unity Robotics Package"}),"\n",(0,t.jsx)(n.p,{children:"To use Unity for robotics simulation, install the Unity Robotics Hub:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Download Unity Hub from the official website"}),"\n",(0,t.jsx)(n.li,{children:"Install Unity 2021.3 LTS or later"}),"\n",(0,t.jsx)(n.li,{children:"Install the Unity Robotics Package via Package Manager"}),"\n",(0,t.jsx)(n.li,{children:"Add the ROS# package for ROS/ROS 2 integration"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2-project-configuration",children:"2. Project Configuration"}),"\n",(0,t.jsx)(n.p,{children:"Create a new Unity project with these settings:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Render Pipeline: Use Universal Render Pipeline (URP) for better performance"}),"\n",(0,t.jsx)(n.li,{children:"Physics: Use PhysX (Unity's built-in physics engine)"}),"\n",(0,t.jsx)(n.li,{children:"Scripting: Use C# with appropriate robotics libraries"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"high-fidelity-visual-rendering",children:"High-Fidelity Visual Rendering"}),"\n",(0,t.jsx)(n.h3,{id:"1-lighting-systems",children:"1. Lighting Systems"}),"\n",(0,t.jsx)(n.p,{children:"Unity provides multiple lighting options for realistic rendering:"}),"\n",(0,t.jsx)(n.h4,{id:"real-time-global-illumination",children:"Real-time Global Illumination"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"// Enable real-time GI for realistic lighting\r\nLightmapping.realtimeGI = true;\r\nLightmapping.bakedGI = true;\n"})}),"\n",(0,t.jsx)(n.h4,{id:"light-probes-for-dynamic-objects",children:"Light Probes for Dynamic Objects"}),"\n",(0,t.jsx)(n.p,{children:"For humanoid robots moving through environments, use light probes to capture lighting variations:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"// Position light probes throughout the environment\r\n// Unity automatically interpolates lighting for dynamic objects\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-material-and-texture-systems",children:"2. Material and Texture Systems"}),"\n",(0,t.jsx)(n.p,{children:"Create realistic materials for humanoid robot components:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'// Example material for robot body\r\npublic class RobotMaterialSetup : MonoBehaviour\r\n{\r\n    void Start()\r\n    {\r\n        Renderer robotRenderer = GetComponent<Renderer>();\r\n        \r\n        // Set metallic and smoothness for robot parts\r\n        robotRenderer.material.SetFloat("_Metallic", 0.8f);\r\n        robotRenderer.material.SetFloat("_Smoothness", 0.6f);\r\n        \r\n        // Add wear and tear textures\r\n        robotRenderer.material.SetTexture("_DetailAlbedoMap", \r\n            Resources.Load<Texture2D>("Textures/robot_wear"));\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"3-shader-considerations",children:"3. Shader Considerations"}),"\n",(0,t.jsx)(n.p,{children:"For photorealistic rendering in robotics:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use physically-based rendering (PBR) shaders"}),"\n",(0,t.jsx)(n.li,{children:"Implement proper normal maps for surface details"}),"\n",(0,t.jsx)(n.li,{children:"Use specular highlights for metallic surfaces"}),"\n",(0,t.jsx)(n.li,{children:"Add environmental reflections"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"perception-specific-rendering-features",children:"Perception-Specific Rendering Features"}),"\n",(0,t.jsx)(n.h3,{id:"1-camera-systems",children:"1. Camera Systems"}),"\n",(0,t.jsx)(n.p,{children:"Unity supports various camera configurations for robotic perception:"}),"\n",(0,t.jsx)(n.h4,{id:"rgb-cameras",children:"RGB Cameras"}),"\n",(0,t.jsx)(n.p,{children:"Standard color cameras for computer vision tasks:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"using UnityEngine;\r\n\r\npublic class RGBCamera : MonoBehaviour\r\n{\r\n    public int width = 640;\r\n    public int height = 480;\r\n    public float fieldOfView = 60f;\r\n    \r\n    private Camera cam;\r\n    private RenderTexture renderTexture;\r\n    \r\n    void Start()\r\n    {\r\n        cam = GetComponent<Camera>();\r\n        cam.fieldOfView = fieldOfView;\r\n        \r\n        // Create render texture for camera output\r\n        renderTexture = new RenderTexture(width, height, 24);\r\n        cam.targetTexture = renderTexture;\r\n    }\r\n    \r\n    // Access rendered image\r\n    public Texture2D GetImage()\r\n    {\r\n        RenderTexture.active = renderTexture;\r\n        Texture2D image = new Texture2D(width, height);\r\n        image.ReadPixels(new Rect(0, 0, width, height), 0, 0);\r\n        image.Apply();\r\n        RenderTexture.active = null;\r\n        return image;\r\n    }\r\n}\n"})}),"\n",(0,t.jsx)(n.h4,{id:"depth-cameras",children:"Depth Cameras"}),"\n",(0,t.jsx)(n.p,{children:"For 3D perception and mapping:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"using UnityEngine;\r\n\r\npublic class DepthCamera : MonoBehaviour\r\n{\r\n    public int width = 640;\r\n    public int height = 480;\r\n    public float maxDistance = 10.0f;\r\n    \r\n    private Camera cam;\r\n    private RenderTexture depthTexture;\r\n    \r\n    void Start()\r\n    {\r\n        cam = GetComponent<Camera>();\r\n        \r\n        // Configure camera for depth rendering\r\n        depthTexture = new RenderTexture(width, height, 24, RenderTextureFormat.RFloat);\r\n        cam.depthTextureMode = DepthTextureMode.Depth;\r\n    }\r\n    \r\n    // Process depth data\r\n    public float[,] GetDepthData()\r\n    {\r\n        RenderTexture.active = depthTexture;\r\n        Texture2D depthTex = new Texture2D(width, height, TextureFormat.RFloat, false);\r\n        depthTex.ReadPixels(new Rect(0, 0, width, height), 0, 0);\r\n        depthTex.Apply();\r\n        \r\n        // Convert to depth values\r\n        float[,] depthData = new float[height, width];\r\n        for (int y = 0; y < height; y++)\r\n        {\r\n            for (int x = 0; x < width; x++)\r\n            {\r\n                Color pixel = depthTex.GetPixel(x, y);\r\n                depthData[y, x] = pixel.r * maxDistance; // Scale to max distance\r\n            }\r\n        }\r\n        \r\n        RenderTexture.active = null;\r\n        return depthData;\r\n    }\r\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-sensor-simulation-pipeline",children:"2. Sensor Simulation Pipeline"}),"\n",(0,t.jsx)(n.p,{children:"Create a comprehensive sensor simulation system:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing System.Collections;\r\n\r\npublic class SensorSimulationPipeline : MonoBehaviour\r\n{\r\n    [Header("Camera Settings")]\r\n    public Camera rgbCamera;\r\n    public Camera depthCamera;\r\n    public Camera semanticCamera;\r\n    \r\n    [Header("Output Settings")]\r\n    public string outputDirectory = "SensorData";\r\n    public int frameRate = 30;\r\n    \r\n    private float frameInterval;\r\n    private int frameCounter = 0;\r\n    \r\n    void Start()\r\n    {\r\n        frameInterval = 1.0f / frameRate;\r\n        StartCoroutine(CaptureSensorData());\r\n    }\r\n    \r\n    IEnumerator CaptureSensorData()\r\n    {\r\n        while (true)\r\n        {\r\n            // Capture RGB image\r\n            Texture2D rgbImage = CaptureCameraImage(rgbCamera);\r\n            SaveImage(rgbImage, $"rgb_frame_{frameCounter:0000}.png");\r\n            \r\n            // Capture depth image\r\n            Texture2D depthImage = CaptureDepthImage(depthCamera);\r\n            SaveImage(depthImage, $"depth_frame_{frameCounter:0000}.png");\r\n            \r\n            // Capture semantic segmentation\r\n            Texture2D semanticImage = CaptureSemanticImage(semanticCamera);\r\n            SaveImage(semanticImage, $"semantic_frame_{frameCounter:0000}.png");\r\n            \r\n            frameCounter++;\r\n            yield return new WaitForSeconds(frameInterval);\r\n        }\r\n    }\r\n    \r\n    Texture2D CaptureCameraImage(Camera cam)\r\n    {\r\n        // Implementation for capturing camera images\r\n        RenderTexture currentRT = RenderTexture.active;\r\n        RenderTexture.active = cam.targetTexture;\r\n        \r\n        Texture2D image = new Texture2D(cam.targetTexture.width, cam.targetTexture.height);\r\n        image.ReadPixels(new Rect(0, 0, cam.targetTexture.width, cam.targetTexture.height), 0, 0);\r\n        image.Apply();\r\n        \r\n        RenderTexture.active = currentRT;\r\n        return image;\r\n    }\r\n    \r\n    void SaveImage(Texture2D image, string filename)\r\n    {\r\n        byte[] bytes = image.EncodeToPNG();\r\n        string path = System.IO.Path.Combine(outputDirectory, filename);\r\n        System.IO.File.WriteAllBytes(path, bytes);\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"environment-creation-for-perception-tasks",children:"Environment Creation for Perception Tasks"}),"\n",(0,t.jsx)(n.h3,{id:"1-indoor-environments",children:"1. Indoor Environments"}),"\n",(0,t.jsx)(n.p,{children:"Create realistic indoor environments for humanoid robot navigation:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class IndoorEnvironmentGenerator : MonoBehaviour\r\n{\r\n    public GameObject[] roomPrefabs;\r\n    public GameObject[] furniturePrefabs;\r\n    public Material[] wallMaterials;\r\n    public Material[] floorMaterials;\r\n    \r\n    [Range(1, 10)]\r\n    public int roomCount = 5;\r\n    \r\n    void Start()\r\n    {\r\n        GenerateEnvironment();\r\n    }\r\n    \r\n    void GenerateEnvironment()\r\n    {\r\n        for (int i = 0; i < roomCount; i++)\r\n        {\r\n            // Instantiate room\r\n            GameObject room = Instantiate(roomPrefabs[Random.Range(0, roomPrefabs.Length)]);\r\n            room.transform.position = new Vector3(i * 10, 0, 0);\r\n            \r\n            // Apply random materials\r\n            ApplyRandomMaterials(room);\r\n            \r\n            // Add furniture\r\n            AddFurniture(room);\r\n        }\r\n    }\r\n    \r\n    void ApplyRandomMaterials(GameObject room)\r\n    {\r\n        Renderer[] renderers = room.GetComponentsInChildren<Renderer>();\r\n        foreach (Renderer renderer in renderers)\r\n        {\r\n            if (renderer.name.Contains("wall"))\r\n            {\r\n                renderer.material = wallMaterials[Random.Range(0, wallMaterials.Length)];\r\n            }\r\n            else if (renderer.name.Contains("floor"))\r\n            {\r\n                renderer.material = floorMaterials[Random.Range(0, floorMaterials.Length)];\r\n            }\r\n        }\r\n    }\r\n    \r\n    void AddFurniture(GameObject room)\r\n    {\r\n        int furnitureCount = Random.Range(3, 8);\r\n        for (int i = 0; i < furnitureCount; i++)\r\n        {\r\n            GameObject furniture = Instantiate(\r\n                furniturePrefabs[Random.Range(0, furniturePrefabs.Length)]);\r\n            \r\n            // Position furniture within room bounds\r\n            Bounds roomBounds = GetRoomBounds(room);\r\n            Vector3 randomPos = new Vector3(\r\n                Random.Range(roomBounds.min.x, roomBounds.max.x),\r\n                0, // At floor level\r\n                Random.Range(roomBounds.min.z, roomBounds.max.z));\r\n                \r\n            furniture.transform.position = randomPos;\r\n        }\r\n    }\r\n    \r\n    Bounds GetRoomBounds(GameObject room)\r\n    {\r\n        // Calculate room boundaries\r\n        Renderer[] renderers = room.GetComponentsInChildren<Renderer>();\r\n        if (renderers.Length == 0) return new Bounds(Vector3.zero, Vector3.one);\r\n        \r\n        Bounds bounds = renderers[0].bounds;\r\n        foreach (Renderer r in renderers)\r\n        {\r\n            bounds.Encapsulate(r.bounds);\r\n        }\r\n        return bounds;\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"2-outdoor-environments",children:"2. Outdoor Environments"}),"\n",(0,t.jsx)(n.p,{children:"For humanoid robots operating outdoors:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class OutdoorEnvironmentGenerator : MonoBehaviour\r\n{\r\n    public GameObject terrainPrefab;\r\n    public GameObject[] treePrefabs;\r\n    public GameObject[] rockPrefabs;\r\n    public GameObject[] buildingPrefabs;\r\n    \r\n    [Header("Environment Settings")]\r\n    public int terrainWidth = 100;\r\n    public int terrainLength = 100;\r\n    public float terrainHeight = 20f;\r\n    \r\n    [Range(0, 1)]\r\n    public float vegetationDensity = 0.3f;\r\n    \r\n    void Start()\r\n    {\r\n        GenerateTerrain();\r\n        AddVegetation();\r\n        AddStructures();\r\n    }\r\n    \r\n    void GenerateTerrain()\r\n    {\r\n        GameObject terrain = Instantiate(terrainPrefab);\r\n        terrain.GetComponent<Terrain>().terrainData.size = \r\n            new Vector3(terrainWidth, terrainHeight, terrainLength);\r\n    }\r\n    \r\n    void AddVegetation()\r\n    {\r\n        int treeCount = Mathf.RoundToInt(vegetationDensity * terrainWidth * terrainLength / 10);\r\n        \r\n        for (int i = 0; i < treeCount; i++)\r\n        {\r\n            GameObject tree = Instantiate(treePrefabs[Random.Range(0, treePrefabs.Length)]);\r\n            \r\n            // Position tree randomly on terrain\r\n            Vector3 pos = new Vector3(\r\n                Random.Range(0, terrainWidth),\r\n                0,\r\n                Random.Range(0, terrainLength));\r\n                \r\n            tree.transform.position = pos;\r\n        }\r\n    }\r\n    \r\n    void AddStructures()\r\n    {\r\n        int buildingCount = Random.Range(3, 8);\r\n        \r\n        for (int i = 0; i < buildingCount; i++)\r\n        {\r\n            GameObject building = Instantiate(buildingPrefabs[Random.Range(0, buildingPrefabs.Length)]);\r\n            \r\n            // Position building\r\n            Vector3 pos = new Vector3(\r\n                Random.Range(10, terrainWidth - 10),\r\n                0,\r\n                Random.Range(10, terrainLength - 10));\r\n                \r\n            building.transform.position = pos;\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"rendering-optimization-for-real-time-performance",children:"Rendering Optimization for Real-time Performance"}),"\n",(0,t.jsx)(n.h3,{id:"1-level-of-detail-lod",children:"1. Level of Detail (LOD)"}),"\n",(0,t.jsx)(n.p,{children:"Implement LOD systems for complex humanoid robots:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"using UnityEngine;\r\n\r\n[RequireComponent(typeof(LODGroup))]\r\npublic class HumanoidLODManager : MonoBehaviour\r\n{\r\n    public float[] lodDistances = {10f, 30f, 60f};\r\n    public Renderer[] lodRenderers;\r\n    \r\n    private LODGroup lodGroup;\r\n    \r\n    void Start()\r\n    {\r\n        lodGroup = GetComponent<LODGroup>();\r\n        \r\n        LOD[] lods = new LOD[lodDistances.Length];\r\n        \r\n        for (int i = 0; i < lodDistances.Length; i++)\r\n        {\r\n            float fadeTransitionWidth = 0.1f;\r\n            lods[i] = new LOD(fadeTransitionWidth, lodRenderers[i]);\r\n            lods[i].screenRelativeTransitionHeight = lodDistances[i] / 100f; // Normalize\r\n        }\r\n        \r\n        lodGroup.SetLODs(lods);\r\n        lodGroup.RecalculateBounds();\r\n    }\r\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-occlusion-culling",children:"2. Occlusion Culling"}),"\n",(0,t.jsx)(n.p,{children:"Enable occlusion culling for complex environments:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class OcclusionCullingSetup : MonoBehaviour\r\n{\r\n    public bool enableOcclusionCulling = true;\r\n    \r\n    void Start()\r\n    {\r\n        if (enableOcclusionCulling)\r\n        {\r\n            // Unity automatically handles occlusion culling\r\n            // when building scenes with static objects marked\r\n            // as "Occluder Static" and "Occludee Static"\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"3-shader-optimization",children:"3. Shader Optimization"}),"\n",(0,t.jsx)(n.p,{children:"Use optimized shaders for real-time performance:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-hlsl",children:'// Simplified PBR shader for real-time robotics simulation\r\nShader "Robotics/SimplePBR"\r\n{\r\n    Properties\r\n    {\r\n        _Color ("Color", Color) = (1,1,1,1)\r\n        _MainTex ("Albedo", 2D) = "white" {}\r\n        _Metallic ("Metallic", Range(0,1)) = 0.0\r\n        _Smoothness ("Smoothness", Range(0,1)) = 0.5\r\n    }\r\n    SubShader\r\n    {\r\n        Tags { "RenderType"="Opaque" }\r\n        LOD 200\r\n\r\n        CGPROGRAM\r\n        #pragma surface surf Standard fullforwardshadows\r\n        #pragma target 3.0\r\n\r\n        struct Input\r\n        {\r\n            float2 uv_MainTex;\r\n        };\r\n\r\n        sampler2D _MainTex;\r\n        fixed4 _Color;\r\n        half _Metallic;\r\n        half _Smoothness;\r\n\r\n        void surf (Input IN, inout SurfaceOutputStandard o)\r\n        {\r\n            fixed4 c = tex2D(_MainTex, IN.uv_MainTex) * _Color;\r\n            o.Albedo = c.rgb;\r\n            o.Metallic = _Metallic;\r\n            o.Smoothness = _Smoothness;\r\n            o.Alpha = c.a;\r\n        }\r\n        ENDCG\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"integration-with-rosros-2",children:"Integration with ROS/ROS 2"}),"\n",(0,t.jsx)(n.h3,{id:"1-ros-integration",children:"1. ROS# Integration"}),"\n",(0,t.jsx)(n.p,{children:"Connect Unity to ROS/ROS 2 using ROS#:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using System.Collections;\r\nusing System.Collections.Generic;\r\nusing UnityEngine;\r\nusing RosSharp.RosBridgeClient;\r\n\r\npublic class UnityROSConnector : MonoBehaviour\r\n{\r\n    public string rosBridgeServerUrl = "ws://192.168.1.1:9090";\r\n    private RosSocket rosSocket;\r\n    \r\n    void Start()\r\n    {\r\n        // Connect to ROS bridge\r\n        WebSocketNativeClient webSocket = new WebSocketNativeClient(rosBridgeServerUrl);\r\n        rosSocket = new RosSocket(webSocket);\r\n        \r\n        // Subscribe to camera topics\r\n        rosSocket.Subscribe<Messages.Sensor.CompressedImage>(\r\n            "/camera/rgb/image_raw/compressed", \r\n            ReceiveImageMessage);\r\n    }\r\n    \r\n    void ReceiveImageMessage(Messages.Sensor.CompressedImage imageMsg)\r\n    {\r\n        // Process received image data\r\n        byte[] imageData = System.Convert.FromBase64String(imageMsg.data);\r\n        \r\n        // Update Unity camera texture with ROS image\r\n        UpdateCameraTexture(imageData);\r\n    }\r\n    \r\n    void UpdateCameraTexture(byte[] imageData)\r\n    {\r\n        // Implementation to update Unity texture with ROS image\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"2-sensor-data-publishing",children:"2. Sensor Data Publishing"}),"\n",(0,t.jsx)(n.p,{children:"Publish sensor data from Unity to ROS:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing RosSharp.RosBridgeClient;\r\nusing RosSharp.Messages.Sensor;\r\n\r\npublic class SensorPublisher : MonoBehaviour\r\n{\r\n    public RosSocket rosSocket;\r\n    public Camera rgbCamera;\r\n    public string imageTopic = "/unity_camera/rgb/image_raw";\r\n    \r\n    private float publishRate = 30.0f; // Hz\r\n    private float lastPublishTime = 0.0f;\r\n    \r\n    void Update()\r\n    {\r\n        float currentTime = Time.time;\r\n        if (currentTime - lastPublishTime > 1.0f / publishRate)\r\n        {\r\n            PublishCameraImage();\r\n            lastPublishTime = currentTime;\r\n        }\r\n    }\r\n    \r\n    void PublishCameraImage()\r\n    {\r\n        Texture2D image = CaptureCameraImage(rgbCamera);\r\n        byte[] imageData = image.EncodeToPNG();\r\n        string base64Image = System.Convert.ToBase64String(imageData);\r\n        \r\n        CompressedImage msg = new CompressedImage\r\n        {\r\n            format = "png",\r\n            data = base64Image\r\n        };\r\n        \r\n        rosSocket.Publish(imageTopic, msg);\r\n    }\r\n    \r\n    Texture2D CaptureCameraImage(Camera cam)\r\n    {\r\n        RenderTexture currentRT = RenderTexture.active;\r\n        RenderTexture.active = cam.targetTexture;\r\n        \r\n        Texture2D image = new Texture2D(cam.targetTexture.width, cam.targetTexture.height);\r\n        image.ReadPixels(new Rect(0, 0, cam.targetTexture.width, cam.targetTexture.height), 0, 0);\r\n        image.Apply();\r\n        \r\n        RenderTexture.active = currentRT;\r\n        return image;\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,t.jsx)(n.h3,{id:"1-frame-rate-optimization",children:"1. Frame Rate Optimization"}),"\n",(0,t.jsx)(n.p,{children:"Maintain consistent frame rates for perception tasks:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Target 30-60 FPS for real-time applications"}),"\n",(0,t.jsx)(n.li,{children:"Use fixed time steps for physics"}),"\n",(0,t.jsx)(n.li,{children:"Optimize rendering quality vs. performance"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2-memory-management",children:"2. Memory Management"}),"\n",(0,t.jsx)(n.p,{children:"Efficiently manage memory for large environments:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use object pooling for frequently instantiated objects"}),"\n",(0,t.jsx)(n.li,{children:"Implement texture streaming"}),"\n",(0,t.jsx)(n.li,{children:"Optimize mesh complexity"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"3-multi-threading",children:"3. Multi-threading"}),"\n",(0,t.jsx)(n.p,{children:"Leverage Unity's multi-threading for sensor processing:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Process sensor data on background threads"}),"\n",(0,t.jsx)(n.li,{children:"Use Unity's Job System for parallel computation"}),"\n",(0,t.jsx)(n.li,{children:"Implement efficient data structures for sensor data"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Unity's rendering capabilities provide unparalleled visual fidelity for humanoid robot perception systems. By combining photorealistic rendering with efficient simulation pipelines, developers can create training and testing environments that closely match real-world conditions, facilitating the development of robust perception algorithms for humanoid robots."})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453(e,n,r){r.d(n,{R:()=>o,x:()=>s});var i=r(6540);const t={},a=i.createContext(t);function o(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);
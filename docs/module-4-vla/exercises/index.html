<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-4-vla/exercises" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">6. Module 4 Exercises | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://physical-ai-book.github.io/physical-ai-book/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://physical-ai-book.github.io/physical-ai-book/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://physical-ai-book.github.io/physical-ai-book/docs/module-4-vla/exercises"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="6. Module 4 Exercises | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="These exercises will challenge you to build and integrate the Vision-Language-Action (VLA) pipeline components we&#x27;ve discussed."><meta data-rh="true" property="og:description" content="These exercises will challenge you to build and integrate the Vision-Language-Action (VLA) pipeline components we&#x27;ve discussed."><link data-rh="true" rel="icon" href="/physical-ai-book/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://physical-ai-book.github.io/physical-ai-book/docs/module-4-vla/exercises"><link data-rh="true" rel="alternate" href="https://physical-ai-book.github.io/physical-ai-book/docs/module-4-vla/exercises" hreflang="en"><link data-rh="true" rel="alternate" href="https://physical-ai-book.github.io/physical-ai-book/docs/module-4-vla/exercises" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Exercises","item":"https://physical-ai-book.github.io/physical-ai-book/docs/module-4-vla/exercises"}]}</script><link rel="alternate" type="application/rss+xml" href="/physical-ai-book/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/physical-ai-book/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Atom Feed"><link rel="stylesheet" href="/physical-ai-book/assets/css/styles.9c53a5ce.css">
<script src="/physical-ai-book/assets/js/runtime~main.c5539952.js" defer="defer"></script>
<script src="/physical-ai-book/assets/js/main.2a4e0f3d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/physical-ai-book/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/physical-ai-book/"><div class="navbar__logo"><img src="/physical-ai-book/img/logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/physical-ai-book/img/logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/physical-ai-book/docs/intro">Textbook</a><a class="navbar__item navbar__link" href="/physical-ai-book/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/physical-ai-book/physical-ai-book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/physical-ai-book/docs/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-book/docs/module-1-ros2/intro-to-ros2"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-book/docs/module-2-digital-twin/what-is-a-digital-twin"><span title="Module 2: The Digital Twin (Gazebo &amp; Unity)" class="categoryLinkLabel_W154">Module 2: The Digital Twin (Gazebo &amp; Unity)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-book/docs/module-3-isaac/intro-to-isaac"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaac™)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaac™)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/physical-ai-book/docs/module-4-vla/vla-future-of-robotics"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module-4-vla/vla-future-of-robotics"><span title="VLA Future of Robotics" class="linkLabel_WmDU">VLA Future of Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module-4-vla/whisper-voice-commands"><span title="Whisper Voice Commands" class="linkLabel_WmDU">Whisper Voice Commands</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module-4-vla/llm-to-ros-actions"><span title="LLM to ROS Actions" class="linkLabel_WmDU">LLM to ROS Actions</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module-4-vla/cognitive-planning-pipelines"><span title="Cognitive Planning Pipelines" class="linkLabel_WmDU">Cognitive Planning Pipelines</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module-4-vla/integrating-vla"><span title="Integrating VLA" class="linkLabel_WmDU">Integrating VLA</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/physical-ai-book/docs/module-4-vla/exercises"><span title="Exercises" class="linkLabel_WmDU">Exercises</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-book/docs/capstone-project/project-walkthrough"><span title="Capstone Project: The Autonomous Humanoid" class="categoryLinkLabel_W154">Capstone Project: The Autonomous Humanoid</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/physical-ai-book/docs/glossary"><span title="Glossary" class="linkLabel_WmDU">Glossary</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/physical-ai-book/docs/appendix"><span title="Appendix" class="linkLabel_WmDU">Appendix</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/physical-ai-book/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 4: Vision-Language-Action (VLA)</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Exercises</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>6. Module 4 Exercises</h1></header>
<p>These exercises will challenge you to build and integrate the Vision-Language-Action (VLA) pipeline components we&#x27;ve discussed.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="exercise-1-customize-your-whisper-node">Exercise 1: Customize Your Whisper Node<a href="#exercise-1-customize-your-whisper-node" class="hash-link" aria-label="Direct link to Exercise 1: Customize Your Whisper Node" title="Direct link to Exercise 1: Customize Your Whisper Node" translate="no">​</a></h2>
<p><strong>Goal</strong>: Modify the <code>whisper_node.py</code> to change its audio capture duration and the Whisper model it uses.</p>
<ol>
<li class="">Open <code>whisper_node.py</code> from Chapter 2.</li>
<li class="">Modify the node&#x27;s parameters (e.g., <code>audio_duration</code>, <code>whisper_model</code>) either directly in the code or by launching the node with <code>ros2 run</code> and passing arguments:<!-- -->
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ros2 run voice_command_pkg whisper_node --ros-args -p audio_duration:=5.0 -p whisper_model:=&#x27;tiny&#x27;</span><br></span></code></pre></div></div>
</li>
<li class=""><strong>Verify</strong>: Confirm the node now records for 5 seconds (or your chosen duration) and, if you chose a smaller model like &#x27;tiny&#x27;, you might notice a slight change in transcription accuracy or speed.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="exercise-2-extend-the-mock-llm-planner">Exercise 2: Extend the Mock LLM Planner<a href="#exercise-2-extend-the-mock-llm-planner" class="hash-link" aria-label="Direct link to Exercise 2: Extend the Mock LLM Planner" title="Direct link to Exercise 2: Extend the Mock LLM Planner" translate="no">​</a></h2>
<p><strong>Goal</strong>: Add new command-action mappings to your <code>mock_llm_planner.py</code>.</p>
<ol>
<li class="">Open <code>mock_llm_planner.py</code> from Chapter 3.</li>
<li class="">Add at least two new natural language commands and their corresponding action sequences. For example:<!-- -->
<ul>
<li class="">&quot;Find the book and tell me where it is.&quot; -&gt; <code>[&quot;say(The book is over there.)&quot;, &quot;find_object(book)&quot;]</code> (you don&#x27;t have to implement <code>find_object</code> yet, just make it an action string).</li>
<li class="">&quot;Dance for me.&quot; -&gt; <code>[&quot;perform_dance_routine()&quot;]</code></li>
</ul>
</li>
<li class="">Rebuild your <code>llm_planner_pkg</code> package.</li>
<li class="">Run your <code>mock_llm_planner</code> node.</li>
<li class=""><strong>Verify</strong>: Use <code>ros2 service call /get_action_plan custom_interfaces/srv/GetActionPlan &quot;command: &#x27;Your new command here.&#x27;&quot;</code> and check if the returned <code>action_plan</code> is as expected.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="exercise-3-implement-a-custom-action-skill">Exercise 3: Implement a Custom Action Skill<a href="#exercise-3-implement-a-custom-action-skill" class="hash-link" aria-label="Direct link to Exercise 3: Implement a Custom Action Skill" title="Direct link to Exercise 3: Implement a Custom Action Skill" translate="no">​</a></h2>
<p><strong>Goal</strong>: Extend the <code>ActionExecutor</code> to handle a new custom robot skill.</p>
<p>This exercise builds on Exercise 2. Let&#x27;s assume you added <code>perform_dance_routine()</code> as a new action.</p>
<ol>
<li class="">Open <code>executor_node.py</code> from Chapter 4.</li>
<li class="">Add a new <code>elif</code> block in the <code>voice_command_callback</code> loop to detect your new action.</li>
<li class="">Implement a new <code>async</code> function, for example, <code>execute_dance_routine(self)</code>. For now, this function can simply print a message like <code>self.get_logger().info(&quot;Robot is dancing!&quot;)</code> and publish to your <code>/robot_speech</code> topic to say &quot;I am dancing!&quot;. In a real robot, this would trigger a complex movement sequence.</li>
<li class="">Rebuild your <code>action_executor_pkg</code> package.</li>
<li class="">Run all necessary nodes: Whisper, Mock LLM, and Action Executor.</li>
<li class=""><strong>Verify</strong>: Speak your new command (&quot;Dance for me!&quot;) into the microphone. Check the logs of the <code>action_executor</code> node and the <code>/robot_speech</code> topic.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="exercise-4-advanced-basic-object-detection-integration">Exercise 4 (Advanced): Basic Object Detection Integration<a href="#exercise-4-advanced-basic-object-detection-integration" class="hash-link" aria-label="Direct link to Exercise 4 (Advanced): Basic Object Detection Integration" title="Direct link to Exercise 4 (Advanced): Basic Object Detection Integration" translate="no">​</a></h2>
<p><strong>Goal</strong>: Simulate a basic object detection system and integrate it with your <code>ActionExecutor</code>.</p>
<ol>
<li class=""><strong>Create a mock object detector node</strong>:<!-- -->
<ul>
<li class="">Create a new Python ROS 2 node, say <code>mock_object_detector.py</code>.</li>
<li class="">This node should periodically publish a <code>geometry_msgs/msg/PoseStamped</code> message to a <code>/detected_objects</code> topic. The message&#x27;s <code>header.frame_id</code> could be &#x27;base_link&#x27;, and its <code>pose.position</code> could represent a known object&#x27;s location (e.g., <code>x=1.0, y=0.5, z=0.0</code>).</li>
<li class="">Publish a <code>std_msgs/msg/String</code> message alongside this, e.g., <code>/detected_object_name</code> with <code>data: &quot;mug&quot;</code>. (For simplicity, assume it only detects one object type).</li>
</ul>
</li>
<li class=""><strong>Modify <code>ActionExecutor</code></strong>:<!-- -->
<ul>
<li class="">Open <code>executor_node.py</code> from Chapter 5.</li>
<li class="">Subscribe to the <code>/detected_objects</code> and <code>/detected_object_name</code> topics. Store the latest detected object&#x27;s name and pose in internal variables.</li>
<li class="">Add a new action to your mock LLM, e.g., &quot;pick up the object.&quot; -&gt; <code>[&quot;pick_up_detected_object()&quot;]</code>.</li>
<li class="">Implement <code>async def execute_pick_up_detected_object(self)</code> in <code>ActionExecutor</code>. This function should retrieve the stored detected object&#x27;s pose and simulate sending a manipulation command (e.g., print a message with the pose).</li>
</ul>
</li>
<li class=""><strong>Verify</strong>:<!-- -->
<ul>
<li class="">Run the <code>mock_object_detector</code>, Whisper, Mock LLM, and Action Executor nodes.</li>
<li class="">Speak &quot;Pick up the object.&quot;</li>
<li class="">Observe the <code>ActionExecutor</code> logs to see if it correctly identifies and &quot;picks up&quot; the object at the simulated detected pose.</li>
</ul>
</li>
</ol>
<hr>
<p>This concludes the VLA module. These exercises demonstrate how the power of language models can be combined with visual perception and robot control to create intelligent, adaptable robotic agents. In the final capstone project, we will bring all these modules together to build a complete autonomous humanoid.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/physical-ai-book/physical-ai-book/tree/main/docs/module-4-vla/6-exercises.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/physical-ai-book/docs/module-4-vla/integrating-vla"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Integrating VLA</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/physical-ai-book/docs/capstone-project/project-walkthrough"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Project Walkthrough</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#exercise-1-customize-your-whisper-node" class="table-of-contents__link toc-highlight">Exercise 1: Customize Your Whisper Node</a></li><li><a href="#exercise-2-extend-the-mock-llm-planner" class="table-of-contents__link toc-highlight">Exercise 2: Extend the Mock LLM Planner</a></li><li><a href="#exercise-3-implement-a-custom-action-skill" class="table-of-contents__link toc-highlight">Exercise 3: Implement a Custom Action Skill</a></li><li><a href="#exercise-4-advanced-basic-object-detection-integration" class="table-of-contents__link toc-highlight">Exercise 4 (Advanced): Basic Object Detection Integration</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Content</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical-ai-book/docs/intro">Textbook</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical-ai-book/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/physical-ai-book/physical-ai-book" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 The Physical AI Book Authors. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>